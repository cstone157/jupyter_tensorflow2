{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4483ddb6-556e-4fb0-9915-1d41b75fc313",
   "metadata": {},
   "source": [
    "# Classification using Attention-based Deep Multiple Instance Learning (MIL).\n",
    "\n",
    "<hr />\n",
    "\n",
    "### Introduction\n",
    "\n",
    "#### What is Multiple Instance Learning (MIL)?\n",
    "\n",
    "Usually, with supervised learning algorithms, the learner receives labels for a set of instances. In the case of MIL, the learner receives labels for a set of bags, each of which contains a set of instances. The bag is labeled positive if it contains at least one positive instance, and negative if it does not contain any.\n",
    "\n",
    "### Motivation\n",
    "\n",
    "It is often assumed in image classification tasks that each image clearly represents a class label. In medical imaging (e.g. computational pathology, etc.) an entire image is represented by a single class label (cancerous/non-cancerous) or a region of interest could be given. However, one will be interested in knowing which patterns in the image is actually causing it to belong to that class. In this context, the image(s) will be divided and the subimages will form the bag of instances.\n",
    "\n",
    "Therefore, the goals are to:\n",
    "\n",
    "<ol>\n",
    "    <li>Learn a model to predict a class label for a bag of instances.</li>\n",
    "    <li>Find out which instances within the bag caused a position class label prediction.</li>\n",
    "</ol>\n",
    "\n",
    "### Implementation\n",
    "\n",
    "The following steps describe how the model works:\n",
    "\n",
    "<ol>\n",
    "    <li>The feature extractor layers extract feature embeddings.</li>\n",
    "    <li>The embeddings are fed into the MIL attention layer to get the attention scores. The layer is designed as permutation-invariant.</li>\n",
    "    <li>Input features and their corresponding attention scores are multiplied together.</li>\n",
    "    <li>The resulting output is passed to a softmax function for classification.</li>\n",
    "</ol>\n",
    "\n",
    "### References\n",
    "\n",
    "<ol>\n",
    "    <li>Attention-based Deep Multiple Instance Learning.</li>\n",
    "    <li>Some of the attention operator code implementation was inspired from https://github.com/utayao/Atten_Deep_MIL.</li>\n",
    "    <li>Imbalanced data tutorial by TensorFlow.</li>\n",
    "</ol>\n",
    "\n",
    "<hr />\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e81ea2-590b-47ae-824a-a86f36fb55a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 03:26:13.851880: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744255574.016592  705068 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744255574.051130  705068 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744255574.405898  705068 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744255574.405975  705068 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744255574.405983  705068 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744255574.405989  705068 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-10 03:26:14.447416: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7abb77d-50b3-40d4-b36b-02b04a2e186c",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "### Create dataset\n",
    "\n",
    "We will create a set of bags and assign their labels according to their contents. If at least one positive instance is available in a bag, the bag is considered as a positive bag. If it does not contain any positive instance, the bag will be considered as negative.\n",
    "\n",
    "#### Configuration parameters\n",
    "\n",
    "<ul>\n",
    "    <li>POSITIVE_CLASS: The desired class to be kept in the positive bag.</li>\n",
    "    <li>BAG_COUNT: The number of training bags.</li>\n",
    "    <li>VAL_BAG_COUNT: The number of validation bags.</li>\n",
    "    <li>BAG_SIZE: The number of instances in a bag.</li>\n",
    "    <li>PLOT_SIZE: The number of bags to plot.</li>\n",
    "    <li>ENSEMBLE_AVG_COUNT: The number of models to create and average together. (Optional: often results in better performance - set to 1 for single model)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c0c5c5b-9db4-431d-846a-196f04f8bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_CLASS = 1\n",
    "BAG_COUNT = 1000\n",
    "VAL_BAG_COUNT = 300\n",
    "BAG_SIZE = 3\n",
    "PLOT_SIZE = 3\n",
    "ENSEMBLE_AVG_COUNT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd609d-98c8-445d-a7b6-9bcdc218a4b6",
   "metadata": {},
   "source": [
    "### Prepare bags\n",
    "\n",
    "Since the attention operator is a permutation-invariant operator, an instance with a positive class label is randomly placed among the instances in the positive bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3acf3d61-89e4-42d0-9edc-ad5cbd13cded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive bags: 299\n",
      "Negative bags: 701\n",
      "Positive bags: 86\n",
      "Negative bags: 214\n"
     ]
    }
   ],
   "source": [
    "def create_bags(input_data, input_labels, positive_class, bag_count, instance_count):\n",
    "    # Set up bags.\n",
    "    bags = []\n",
    "    bag_labels = []\n",
    "\n",
    "    # Normalize input data.\n",
    "    input_data = np.divide(input_data, 255.0)\n",
    "\n",
    "    # Count positive samples.\n",
    "    count = 0\n",
    "\n",
    "    for _ in range(bag_count):\n",
    "        # Pick a fixed size random subset of samples.\n",
    "        index = np.random.choice(input_data.shape[0], instance_count, replace=False)\n",
    "        instances_data = input_data[index]\n",
    "        instances_labels = input_labels[index]\n",
    "\n",
    "        # By default, all bags are labeled as 0.\n",
    "        bag_label = 0\n",
    "\n",
    "        # Check if there is at least a positive class in the bag.\n",
    "        if positive_class in instances_labels:\n",
    "            # Positive bag will be labeled as 1.\n",
    "            bag_label = 1\n",
    "            count += 1\n",
    "\n",
    "        bags.append(instances_data)\n",
    "        bag_labels.append(np.array([bag_label]))\n",
    "\n",
    "    print(f\"Positive bags: {count}\")\n",
    "    print(f\"Negative bags: {bag_count - count}\")\n",
    "\n",
    "    return (list(np.swapaxes(bags, 0, 1)), np.array(bag_labels))\n",
    "\n",
    "\n",
    "# Load the MNIST dataset.\n",
    "(x_train, y_train), (x_val, y_val) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Create training data.\n",
    "train_data, train_labels = create_bags(\n",
    "    x_train, y_train, POSITIVE_CLASS, BAG_COUNT, BAG_SIZE\n",
    ")\n",
    "\n",
    "# Create validation data.\n",
    "val_data, val_labels = create_bags(\n",
    "    x_val, y_val, POSITIVE_CLASS, VAL_BAG_COUNT, BAG_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9fc58-9664-4e41-9b6c-f8c12130f1ea",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "### Create the model\n",
    "\n",
    "We will now build the attention layer, prepare some utilities, then build and train the entire model.\n",
    "\n",
    "#### Attention operator implementation\n",
    "\n",
    "The output size of this layer is decided by the size of a single bag.\n",
    "\n",
    "The attention mechanism uses a weighted average of instances in a bag, in which the sum of the weights must equal to 1 (invariant of the bag size).\n",
    "\n",
    "The weight matrices (parameters) are w and v. To include positive and negative values, hyperbolic tangent element-wise non-linearity is utilized.\n",
    "\n",
    "A <b>Gated attention mechanism</b> can be used to deal with complex relations. Another weight matrix, u, is added to the computation. A sigmoid non-linearity is used to overcome approximately linear behavior for x ∈ [−1, 1] by hyperbolic tangent non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0633835e-db2b-418c-aa31-98650997290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MILAttentionLayer(layers.Layer):\n",
    "    \"\"\"Implementation of the attention-based Deep MIL layer.\n",
    "\n",
    "    Args:\n",
    "      weight_params_dim: Positive Integer. Dimension of the weight matrix.\n",
    "      kernel_initializer: Initializer for the `kernel` matrix.\n",
    "      kernel_regularizer: Regularizer function applied to the `kernel` matrix.\n",
    "      use_gated: Boolean, whether or not to use the gated mechanism.\n",
    "\n",
    "    Returns:\n",
    "      List of 2D tensors with BAG_SIZE length.\n",
    "      The tensors are the attention scores after softmax with shape `(batch_size, 1)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        weight_params_dim,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        kernel_regularizer=None,\n",
    "        use_gated=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.weight_params_dim = weight_params_dim\n",
    "        self.use_gated = use_gated\n",
    "\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "\n",
    "        self.v_init = self.kernel_initializer\n",
    "        self.w_init = self.kernel_initializer\n",
    "        self.u_init = self.kernel_initializer\n",
    "\n",
    "        self.v_regularizer = self.kernel_regularizer\n",
    "        self.w_regularizer = self.kernel_regularizer\n",
    "        self.u_regularizer = self.kernel_regularizer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Input shape.\n",
    "        # List of 2D tensors with shape: (batch_size, input_dim).\n",
    "        input_dim = input_shape[0][1]\n",
    "\n",
    "        self.v_weight_params = self.add_weight(\n",
    "            shape=(input_dim, self.weight_params_dim),\n",
    "            initializer=self.v_init,\n",
    "            name=\"v\",\n",
    "            regularizer=self.v_regularizer,\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        self.w_weight_params = self.add_weight(\n",
    "            shape=(self.weight_params_dim, 1),\n",
    "            initializer=self.w_init,\n",
    "            name=\"w\",\n",
    "            regularizer=self.w_regularizer,\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        if self.use_gated:\n",
    "            self.u_weight_params = self.add_weight(\n",
    "                shape=(input_dim, self.weight_params_dim),\n",
    "                initializer=self.u_init,\n",
    "                name=\"u\",\n",
    "                regularizer=self.u_regularizer,\n",
    "                trainable=True,\n",
    "            )\n",
    "        else:\n",
    "            self.u_weight_params = None\n",
    "\n",
    "        self.input_built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Assigning variables from the number of inputs.\n",
    "        instances = [self.compute_attention_scores(instance) for instance in inputs]\n",
    "\n",
    "        # Stack instances into a single tensor.\n",
    "        instances = ops.stack(instances)\n",
    "\n",
    "        # Apply softmax over instances such that the output summation is equal to 1.\n",
    "        alpha = ops.softmax(instances, axis=0)\n",
    "\n",
    "        # Split to recreate the same array of tensors we had as inputs.\n",
    "        return [alpha[i] for i in range(alpha.shape[0])]\n",
    "\n",
    "    def compute_attention_scores(self, instance):\n",
    "        # Reserve in-case \"gated mechanism\" used.\n",
    "        original_instance = instance\n",
    "\n",
    "        # tanh(v*h_k^T)\n",
    "        instance = ops.tanh(ops.tensordot(instance, self.v_weight_params, axes=1))\n",
    "\n",
    "        # for learning non-linear relations efficiently.\n",
    "        if self.use_gated:\n",
    "            instance = instance * ops.sigmoid(\n",
    "                ops.tensordot(original_instance, self.u_weight_params, axes=1)\n",
    "            )\n",
    "\n",
    "        # w^T*(tanh(v*h_k^T)) / w^T*(tanh(v*h_k^T)*sigmoid(u*h_k^T))\n",
    "        return ops.tensordot(instance, self.w_weight_params, axes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e5b43-c35f-4873-8a46-a77a5838c608",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "### Visualizer tool\n",
    "\n",
    "Plot the number of bags (given by PLOT_SIZE) with respect to the class.\n",
    "\n",
    "Moreover, if activated, the class label prediction with its associated instance score for each bag (after the model has been trained) can be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef9e8b3-e819-4ac3-a21c-e98d382f4b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data, labels, bag_class, predictions=None, attention_weights=None):\n",
    "    \"\"\" \"Utility for plotting bags and attention weights.\n",
    "\n",
    "    Args:\n",
    "      data: Input data that contains the bags of instances.\n",
    "      labels: The associated bag labels of the input data.\n",
    "      bag_class: String name of the desired bag class.\n",
    "        The options are: \"positive\" or \"negative\".\n",
    "      predictions: Class labels model predictions.\n",
    "      If you don't specify anything, ground truth labels will be used.\n",
    "      attention_weights: Attention weights for each instance within the input data.\n",
    "      If you don't specify anything, the values won't be displayed.\n",
    "    \"\"\"\n",
    "    return  ## TODO\n",
    "    labels = np.array(labels).reshape(-1)\n",
    "\n",
    "    if bag_class == \"positive\":\n",
    "        if predictions is not None:\n",
    "            labels = np.where(predictions.argmax(1) == 1)[0]\n",
    "            bags = np.array(data)[:, labels[0:PLOT_SIZE]]\n",
    "\n",
    "        else:\n",
    "            labels = np.where(labels == 1)[0]\n",
    "            bags = np.array(data)[:, labels[0:PLOT_SIZE]]\n",
    "\n",
    "    elif bag_class == \"negative\":\n",
    "        if predictions is not None:\n",
    "            labels = np.where(predictions.argmax(1) == 0)[0]\n",
    "            bags = np.array(data)[:, labels[0:PLOT_SIZE]]\n",
    "        else:\n",
    "            labels = np.where(labels == 0)[0]\n",
    "            bags = np.array(data)[:, labels[0:PLOT_SIZE]]\n",
    "\n",
    "    else:\n",
    "        print(f\"There is no class {bag_class}\")\n",
    "        return\n",
    "\n",
    "    print(f\"The bag class label is {bag_class}\")\n",
    "    for i in range(PLOT_SIZE):\n",
    "        figure = plt.figure(figsize=(8, 8))\n",
    "        print(f\"Bag number: {labels[i]}\")\n",
    "        for j in range(BAG_SIZE):\n",
    "            image = bags[j][i]\n",
    "            figure.add_subplot(1, BAG_SIZE, j + 1)\n",
    "            plt.grid(False)\n",
    "            if attention_weights is not None:\n",
    "                plt.title(np.around(attention_weights[labels[i]][j], 2))\n",
    "            plt.imshow(image)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Plot some of validation data bags per class.\n",
    "plot(val_data, val_labels, \"positive\")\n",
    "plot(val_data, val_labels, \"negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3745677-529b-47cd-b465-21864c8b071b",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "### Create model\n",
    "\n",
    "First we will create some embeddings per instance, invoke the attention operator and then use the softmax function to output the class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27236e16-5bbe-4d90-8eb4-878a0e2ef886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(instance_shape):\n",
    "    # Extract features from inputs.\n",
    "    inputs, embeddings = [], []\n",
    "    shared_dense_layer_1 = layers.Dense(128, activation=\"relu\")\n",
    "    shared_dense_layer_2 = layers.Dense(64, activation=\"relu\")\n",
    "    for _ in range(BAG_SIZE):\n",
    "        inp = layers.Input(instance_shape)\n",
    "        flatten = layers.Flatten()(inp)\n",
    "        dense_1 = shared_dense_layer_1(flatten)\n",
    "        dense_2 = shared_dense_layer_2(dense_1)\n",
    "        inputs.append(inp)\n",
    "        embeddings.append(dense_2)\n",
    "\n",
    "    # Invoke the attention layer.\n",
    "    alpha = MILAttentionLayer(\n",
    "        weight_params_dim=256,\n",
    "        kernel_regularizer=keras.regularizers.L2(0.01),\n",
    "        use_gated=True,\n",
    "        name=\"alpha\",\n",
    "    )(embeddings)\n",
    "\n",
    "    # Multiply attention weights with the input layers.\n",
    "    multiply_layers = [\n",
    "        layers.multiply([alpha[i], embeddings[i]]) for i in range(len(alpha))\n",
    "    ]\n",
    "\n",
    "    # Concatenate layers.\n",
    "    concat = layers.concatenate(multiply_layers, axis=1)\n",
    "\n",
    "    # Classification output node.\n",
    "    output = layers.Dense(2, activation=\"softmax\")(concat)\n",
    "\n",
    "    return keras.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91befe4d-cdc6-418f-b564-d214d45f3ef1",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "### Class weights\n",
    "\n",
    "Since this kind of problem could simply turn into imbalanced data classification problem, class weighting should be considered.\n",
    "\n",
    "Let's say there are 1000 bags. There often could be cases were ~90 % of the bags do not contain any positive label and ~10 % do. Such data can be referred to as Imbalanced data.\n",
    "\n",
    "Using class weights, the model will tend to give a higher weight to the rare class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd66bd23-370f-4369-819b-6f03956bd644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(labels):\n",
    "    # Count number of positive and negative bags.\n",
    "    negative_count = len(np.where(labels == 0)[0])\n",
    "    positive_count = len(np.where(labels == 1)[0])\n",
    "    total_count = negative_count + positive_count\n",
    "\n",
    "    # Build class weight dictionary.\n",
    "    return {\n",
    "        0: (1 / negative_count) * (total_count / 2),\n",
    "        1: (1 / positive_count) * (total_count / 2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c04525c-22c3-4725-8950-484960835b7a",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "### Build and train model\n",
    "\n",
    "The model is built and trained in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa683aac-4c08-4952-a650-73f1ee5dbd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 03:07:39.451579: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ alpha               │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>),       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MILAttentionLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)]               │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ alpha[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ alpha[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ alpha[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m100,480\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ alpha               │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m),       │     \u001b[38;5;34m33,024\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mMILAttentionLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, │            │ dense_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)]               │            │ dense_1[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ alpha[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ alpha[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ dense_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ alpha[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ dense_1[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m386\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">142,146</span> (555.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m142,146\u001b[0m (555.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">142,146</span> (555.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m142,146\u001b[0m (555.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor', 'keras_tensor_4', 'keras_tensor_8']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [00:24<00:00, 24.08s/it]\n"
     ]
    }
   ],
   "source": [
    "def train(train_data, train_labels, val_data, val_labels, model):\n",
    "    # Train model.\n",
    "    # Prepare callbacks.\n",
    "    # Path where to save best weights.\n",
    "\n",
    "    # Take the file name from the wrapper.\n",
    "    file_path = \"/tmp/best_model.weights.h5\"\n",
    "\n",
    "    # Initialize model checkpoint callback.\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        file_path,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        mode=\"min\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    # Initialize early stopping callback.\n",
    "    # The model performance is monitored across the validation data and stops training\n",
    "    # when the generalization error cease to decrease.\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=10, mode=\"min\"\n",
    "    )\n",
    "\n",
    "    # Compile model.\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    # Fit model.\n",
    "    model.fit(\n",
    "        train_data,\n",
    "        train_labels,\n",
    "        validation_data=(val_data, val_labels),\n",
    "        epochs=20,\n",
    "        class_weight=compute_class_weights(train_labels),\n",
    "        batch_size=1,\n",
    "        callbacks=[early_stopping, model_checkpoint],\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Load best weights.\n",
    "    model.load_weights(file_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Building model(s).\n",
    "instance_shape = train_data[0][0].shape\n",
    "models = [create_model(instance_shape) for _ in range(ENSEMBLE_AVG_COUNT)]\n",
    "\n",
    "# Show single model architecture.\n",
    "print(models[0].summary())\n",
    "\n",
    "# Training model(s).\n",
    "trained_models = [\n",
    "    train(train_data, train_labels, val_data, val_labels, model)\n",
    "    for model in tqdm(models)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287db408-42f7-4b1f-ae27-434652018523",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "### Model evaluation\n",
    "\n",
    "The models are now ready for evaluation. With each model we also create an associated intermediate model to get the weights from the attention layer.\n",
    "\n",
    "We will compute a prediction for each of our ENSEMBLE_AVG_COUNT models, and average them together for our final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c15c380-1ce7-4cfa-9e26-e01241206cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "The average loss and accuracy are 0.05 and 98.67 % resp.\n"
     ]
    }
   ],
   "source": [
    "def predict(data, labels, trained_models):\n",
    "    # Collect info per model.\n",
    "    models_predictions = []\n",
    "    models_attention_weights = []\n",
    "    models_losses = []\n",
    "    models_accuracies = []\n",
    "\n",
    "    for model in trained_models:\n",
    "        # Predict output classes on data.\n",
    "        predictions = model.predict(data)\n",
    "        models_predictions.append(predictions)\n",
    "\n",
    "        # Create intermediate model to get MIL attention layer weights.\n",
    "        intermediate_model = keras.Model(model.input, model.get_layer(\"alpha\").output)\n",
    "\n",
    "        # Predict MIL attention layer weights.\n",
    "        intermediate_predictions = intermediate_model.predict(data)\n",
    "\n",
    "        attention_weights = np.squeeze(np.swapaxes(intermediate_predictions, 1, 0))\n",
    "        models_attention_weights.append(attention_weights)\n",
    "\n",
    "        loss, accuracy = model.evaluate(data, labels, verbose=0)\n",
    "        models_losses.append(loss)\n",
    "        models_accuracies.append(accuracy)\n",
    "\n",
    "    print(\n",
    "        f\"The average loss and accuracy are {np.sum(models_losses, axis=0) / ENSEMBLE_AVG_COUNT:.2f}\"\n",
    "        f\" and {100 * np.sum(models_accuracies, axis=0) / ENSEMBLE_AVG_COUNT:.2f} % resp.\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        np.sum(models_predictions, axis=0) / ENSEMBLE_AVG_COUNT,\n",
    "        np.sum(models_attention_weights, axis=0) / ENSEMBLE_AVG_COUNT,\n",
    "    )\n",
    "\n",
    "\n",
    "# Evaluate and predict classes and attention scores on validation data.\n",
    "class_predictions, attention_params = predict(val_data, val_labels, trained_models)\n",
    "\n",
    "# Plot some results from our validation data.\n",
    "plot(\n",
    "    val_data,\n",
    "    val_labels,\n",
    "    \"positive\",\n",
    "    predictions=class_predictions,\n",
    "    attention_weights=attention_params,\n",
    ")\n",
    "plot(\n",
    "    val_data,\n",
    "    val_labels,\n",
    "    \"negative\",\n",
    "    predictions=class_predictions,\n",
    "    attention_weights=attention_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf05cac-ce4e-4fd4-bbd7-35a007d38d24",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "From the above plot, you can notice that the weights always sum to 1. In a positively predict bag, the instance which resulted in the positive labeling will have a substantially higher attention score than the rest of the bag. However, in a negatively predicted bag, there are two cases:\n",
    "\n",
    "<ul>\n",
    "    <li>All instances will have approximately similar scores.</li>\n",
    "    <li>An instance will have relatively higher score (but not as high as of a positive instance). This is because the feature space of this instance is close to that of the positive instance.</li>\n",
    "</ul>\n",
    "\n",
    "<hr />\n",
    "\n",
    "### Remarks\n",
    "\n",
    "<ul>\n",
    "    <li>If the model is overfit, the weights will be equally distributed for all bags. Hence, the regularization techniques are necessary.</li>\n",
    "    <li>In the paper, the bag sizes can differ from one bag to another. For simplicity, the bag sizes are fixed here.</li>\n",
    "    <li>In order not to rely on the random initial weights of a single model, averaging ensemble methods should be considered.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9273c7e1-5fa4-40a6-9932-bfedba2d0eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
