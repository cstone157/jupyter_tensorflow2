{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05173163-1381-4bb3-8e82-695ead78bbd9",
   "metadata": {},
   "source": [
    "## Image classification via fine-tuning with EfficientNet\n",
    "\n",
    "<hr />\n",
    "\n",
    "### Introduction: what is EfficientNet\n",
    "\n",
    "EfficientNet, first introduced in Tan and Le, 2019 is among the most efficient models (i.e. requiring least FLOPS for inference) that reaches State-of-the-Art accuracy on both imagenet and common image classification transfer learning tasks.\n",
    "\n",
    "The smallest base model is similar to MnasNet, which reached near-SOTA with a significantly smaller model. By introducing a heuristic way to scale the model, EfficientNet provides a family of models (B0 to B7) that represents a good combination of efficiency and accuracy on a variety of scales. Such a scaling heuristics (compound-scaling, details see Tan and Le, 2019) allows the efficiency-oriented base model (B0) to surpass models at every scale, while avoiding extensive grid-search of hyperparameters.\n",
    "\n",
    "A summary of the latest updates on the model is available at here, where various augmentation schemes and semi-supervised learning approaches are applied to further improve the imagenet performance of the models. These extensions of the model can be used by updating weights without changing model architecture.\n",
    "\n",
    "<hr />\n",
    "\n",
    "### B0 to B7 variants of EfficientNet\n",
    "\n",
    "(This section provides some details on \"compound scaling\", and can be skipped if you're only interested in using the models)\n",
    "\n",
    "Based on the original paper people may have the impression that EfficientNet is a continuous family of models created by arbitrarily choosing scaling factor in as Eq.(3) of the paper. However, choice of resolution, depth and width are also restricted by many factors:\n",
    "\n",
    "<ul>\n",
    "    <li>Resolution: Resolutions not divisible by 8, 16, etc. cause zero-padding near boundaries of some layers which wastes computational resources. This especially applies to smaller variants of the model, hence the input resolution for B0 and B1 are chosen as 224 and 240.</li>\n",
    "    <li>Depth and width: The building blocks of EfficientNet demands channel size to be multiples of 8.</li>\n",
    "    <li>Resource limit: Memory limitation may bottleneck resolution when depth and width can still increase. In such a situation, increasing depth and/or width but keep resolution can still improve performance.</li>\n",
    "</ul>\n",
    "\n",
    "As a result, the depth, width and resolution of each variant of the EfficientNet models are hand-picked and proven to produce good results, though they may be significantly off from the compound scaling formula. Therefore, the keras implementation (detailed below) only provide these 8 models, B0 to B7, instead of allowing arbitray choice of width / depth / resolution parameters.\n",
    "\n",
    "<hr />\n",
    "\n",
    "### Keras implementation of EfficientNet\n",
    "\n",
    "An implementation of EfficientNet B0 to B7 has been shipped with Keras since v2.3. To use EfficientNetB0 for classifying 1000 classes of images from ImageNet, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5ba422-e209-4811-9db9-1e850f133fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 03:26:47.070004: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743910007.225303  535283 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743910007.289478  535283 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743910007.646089  535283 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743910007.646168  535283 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743910007.646175  535283 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743910007.646180  535283 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-06 03:26:47.693729: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-06 03:26:51.505094: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0.h5\n",
      "\u001b[1m21834768/21834768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "model = EfficientNetB0(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df5075f-96e2-4fba-8de7-c0e1bb54e641",
   "metadata": {},
   "source": [
    "This model takes input images of shape (224, 224, 3), and the input data should be in the range [0, 255]. Normalization is included as part of the model.\n",
    "\n",
    "Because training EfficientNet on ImageNet takes a tremendous amount of resources and several techniques that are not a part of the model architecture itself. Hence the Keras implementation by default loads pre-trained weights obtained via training with AutoAugment.\n",
    "\n",
    "For B0 to B7 base models, the input shapes are different. Here is a list of input shape expected for each model:\n",
    "\n",
    "<table>\n",
    "    <tr><th>Base model</th><th>resolution</th></tr>\n",
    "    <tr><td>EfficientNetB0</td><td>224</td></tr>\n",
    "    <tr><td>EfficientNetB1</td><td>240</td></tr>\n",
    "    <tr><td>EfficientNetB2</td><td>260</td></tr>\n",
    "    <tr><td>EfficientNetB3</td><td>300</td></tr>\n",
    "    <tr><td>EfficientNetB4</td><td>380</td></tr>\n",
    "    <tr><td>EfficientNetB5</td><td>456</td></tr>\n",
    "    <tr><td>EfficientNetB6</td><td>528</td></tr>\n",
    "    <tr><td>EfficientNetB7</td><td>600</td></tr>\n",
    "</table>\n",
    "\n",
    "When the model is intended for transfer learning, the Keras implementation provides a option to remove the top layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b41f87-9a80-4014-b4f9-90f792a2bec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNetB0(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b3bcc-2071-44e1-af63-88b28dc60b15",
   "metadata": {},
   "source": [
    "This option excludes the final Dense layer that turns 1280 features on the penultimate layer into prediction of the 1000 ImageNet classes. Replacing the top layer with custom layers allows using EfficientNet as a feature extractor in a transfer learning workflow.\n",
    "\n",
    "Another argument in the model constructor worth noticing is drop_connect_rate which controls the dropout rate responsible for stochastic depth. This parameter serves as a toggle for extra regularization in finetuning, but does not affect loaded weights. For example, when stronger regularization is desired, try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16d76d1b-e496-4764-99ee-40b738d6ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = EfficientNetB0(weights='imagenet', drop_connect_rate=0.4)\n",
    "model = EfficientNetB0(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417f3e4c-6833-4458-87d6-b276630b923f",
   "metadata": {},
   "source": [
    "The default value is 0.2.\n",
    "\n",
    "<hr />\n",
    "\n",
    "### Example: EfficientNetB0 for Stanford Dogs.\n",
    "\n",
    "EfficientNet is capable of a wide range of image classification tasks. This makes it a good model for transfer learning. As an end-to-end example, we will show using pre-trained EfficientNetB0 on Stanford Dogs dataset.\n",
    "\n",
    "<hr />\n",
    "\n",
    "### Setup and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c6db69-8995-4e5a-9d4d-d087232c9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf  # For tf.data\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.applications import EfficientNetB0\n",
    "\n",
    "# IMG_SIZE is determined by EfficientNet model choice\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe80514-e201-4858-af59-94048fd2ff15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
