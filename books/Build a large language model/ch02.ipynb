{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqc7AXIZwE629Osl5XjBl5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["-----\n","Build a Large Language Model\n","Sebastian Raschka\n","-----\n","\n","# Working with text data\n","\n","  - During the pretraining stage, LLMs process text, one word at a time.\n","\n","## 2.1 - Understanding word embeddings\n","\n","  - Converting data into a vector format is referred to as embedding.  An embedding is a mapping from discrete objects, such as words, images, or even entire documents, to point in a continuous vector space - the primary purpose of embeddings is to convert nonnumeric data into a format that neural networks can process.\n","  - In addition to word embeddings, there are also embedding for sentences, paragraphs, or whole documents.\n","  - Retrieval-augmented generation combines generation (like producting text) with retrieval (like searching an external knowledge base) to pull relevant information when generating text.\n","\n","## 2.2 - Tokenizing text\n","\n","  -\n","\n","\n"],"metadata":{"id":"KYlZjvsSZr88"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nhIOhqVnZrW8"},"outputs":[],"source":[]}]}