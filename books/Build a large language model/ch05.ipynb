{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TPQpy_PLJiw",
        "outputId": "bfb5ed0d-a3a4-4bd8-d19c-da001dbaf581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.8.0+cu126\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "print(\"torch version:\", version(\"torch\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzQx4mxrLTNY",
        "outputId": "264ecb57-5d8a-46fe-9d26-b4d4843563f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D2SgL7aNMLg7"
      },
      "outputs": [],
      "source": [
        "## Import code from previous chapters\n",
        "import torch.nn as nn\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True)\n",
        "    var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "    norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "    return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return 0.5 * x * (1 + torch.tanh(\n",
        "        torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "        (x + 0.44715 * torch.pow(x, 3))\n",
        "    ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "        GELU(),\n",
        "        nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out,\n",
        "               context_length, dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    assert (d_out % num_heads == 0), \\\n",
        "        \"d_out must be divisible by num_heads\"\n",
        "\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.out_proj = nn.Linear(d_out, d_out)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "        \"mask\",\n",
        "        torch.triu(torch.ones(context_length, context_length),\n",
        "                   diagonal=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    queries = queries.view(\n",
        "        b, num_tokens, self.num_heads, self.head_dim\n",
        "    )\n",
        "\n",
        "    keys = keys.transpose(1, 2)\n",
        "    queries = queries.transpose(1, 2)\n",
        "    values = values.transpose(1, 2)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(2, 3)\n",
        "    mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "    attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores / keys.shape[-1]**0.5, dim = -1\n",
        "    )\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "    context_vec = context_vec.contiguous().view(\n",
        "        b, num_tokens, self.d_out\n",
        "    )\n",
        "    context_vec = self.out_proj(context_vec)\n",
        "    return context_vec\n",
        "\n",
        "#   The transformer block component of GPT\n",
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.att = MultiHeadAttention(\n",
        "        d_in = cfg[\"emb_dim\"],\n",
        "        d_out = cfg[\"emb_dim\"],\n",
        "        context_length = cfg[\"context_length\"],\n",
        "        num_heads = cfg[\"n_heads\"],\n",
        "        dropout = cfg[\"drop_rate\"],\n",
        "        qkv_bias = cfg[\"qkv_bias\"])\n",
        "\n",
        "    self.ff = FeedForward(cfg)\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self, x):\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.att(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.ff(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "    return x\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "        *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(\n",
        "        cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False\n",
        "    )\n",
        "\n",
        "  def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "\n",
        "    pos_embeds = self.pos_emb(\n",
        "      torch.arange(seq_len, device=in_idx.device)\n",
        "    )\n",
        "\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x)\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhZKiRRFLWzV"
      },
      "source": [
        "# Pretraining on unlabeled data\n",
        "\n",
        "## 5.1 - Evaluating generative text models\n",
        "\n",
        "### 5.1.1 - Using GPT to generate text\n",
        "\n",
        "  - Let's set up the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZsJqYy7LYF7",
        "outputId": "8af1b13f-b97b-456d-be9f-b3630b32be18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 256,  # Context length\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_ow4GowNXJ8",
        "outputId": "8cdd25ed-9c2a-42e9-924f-96d255657b39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text: \n",
            " Every effort moves you rentingetic wasnم refres RexAngel infieldcigans\n"
          ]
        }
      ],
      "source": [
        "#   Utility functions for text to token ID conversion\n",
        "import tiktoken\n",
        "\n",
        "def generate_text_simple(model, idx,\n",
        "        max_new_tokens, context_size):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "\n",
        "    logits = logits[:, -1, :]\n",
        "    probas = torch.softmax(logits, dim=-1)\n",
        "    idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "  return idx\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "  flat = token_ids.squeeze(0)\n",
        "  return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model = model,\n",
        "    idx = text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens = 10,\n",
        "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text: \\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hXZDvTCPvm9"
      },
      "source": [
        "  - The model isn't yet producing coherent text.\n",
        "  - Next, we will calculate a loss metric for the generated outputs.\n",
        "\n",
        "### 5.1.2 - calculating the text generation loss\n",
        "\n",
        "  - Techniques for numerically assessing text quality generated during training by calculating a text generation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdCB3aGHPrjn",
        "outputId": "a55985c9-b0c1-44c1-ba49-92b39e05cdcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ],
      "source": [
        "#   Consider two input examples, which have already been mapped\n",
        "inputs = torch.tensor([[16833, 3626, 6100],  # [\"every effort moves\",\n",
        "                       [40,    1107, 588]])  # \"I really like\"]\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345],     # [\" effort moves you\",\n",
        "                        [1107, 588,  11311]])  # \"really like chocolate\"]\n",
        "\n",
        "#   Now feed the inputs into model to calculate logits vectors for thewo input\n",
        "# examples, each of three tokens.\n",
        "with torch.no_grad():\n",
        "  logits = model(inputs)\n",
        "probas = torch.softmax(logits, dim = -1)\n",
        "print(probas.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhT34tQUO4iQ",
        "outputId": "d755ca50-de34-4ed5-9197-e5b10eecf0f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[16657],\n",
            "         [  339],\n",
            "         [42826]],\n",
            "\n",
            "        [[49906],\n",
            "         [29669],\n",
            "         [41751]]])\n"
          ]
        }
      ],
      "source": [
        "#   The first number, 2, corresponds to the two examples (rows)\n",
        "#\n",
        "#   The second number, 3, corresponds to the number of tokens in each input (row)\n",
        "#\n",
        "#   The last number corresponds to the embedding dimensionality, which is determined\n",
        "# by the vocabulary size.\n",
        "\n",
        "#   Following the conversion from logits to probabilities via the softmax function,\n",
        "# the generate_text_simple function then converts the resulting probability scores\n",
        "# back into text\n",
        "token_ids = torch.argmax(probas, dim = -1, keepdim = True)\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY_L8W4BPOar",
        "outputId": "403d8f39-effc-4753-b2bd-8ca08f707fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 2:  Armed heNetflix\n"
          ]
        }
      ],
      "source": [
        "#   Finally convert the token IDs back into text:\n",
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "print(f\"Outputs batch 2: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A721cjYAXHFV"
      },
      "source": [
        "  - Now we need to evaluate the performance of the model's generated text numerically via a loss.  \n",
        "  - This is useful for measuring the quality of the generated text, but also as a building block for implementing training function.\n",
        "  - Part of text evaluation process that we implement, is to measure \"how far\" the generated tokens are from correct predictions (targets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZbeyZhGXExr",
        "outputId": "3570d32b-8e37-4eb5-efad-e95aa0259bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([7.2671e-05, 3.1046e-05, 1.1696e-05])\n",
            "Text 2: tensor([1.0426e-05, 5.4604e-05, 4.7716e-06])\n"
          ]
        }
      ],
      "source": [
        "#   For each of the two input texts, we can print the initial softmax\n",
        "# probability scores corresponding to the target torkens using the following code:\n",
        "text_idx = 0\n",
        "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 1:\", target_probas_1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probas_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS5Al7ERY5Xt"
      },
      "source": [
        "  - The goal of training an LLM is to maximize the likelihood of the correct token, which involves increasing its probability relative to other tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC8UGhweY1IE",
        "outputId": "3622b880-e5e6-405d-d1b3-5f088d83c86e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ -9.5296, -10.3800, -11.3563, -11.4712,  -9.8154, -12.2528])\n"
          ]
        }
      ],
      "source": [
        "#   Next, we calculate the loss for the probability scores of the two example batches.\n",
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(log_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQndsbkxZXDD",
        "outputId": "e74200df-8967-4608-e816-e866dfe26ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10.8009)\n"
          ]
        }
      ],
      "source": [
        "#   Next we combine these log probabilities into a single score\n",
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVDDBgiraM3p",
        "outputId": "dde6047e-4037-45b9-e984-1b5196b76205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.8009)\n"
          ]
        }
      ],
      "source": [
        "#   The goal is to get the average log probability as close to 0 as possible by\n",
        "# updating the model's weights as part of the training process.\n",
        "#\n",
        "#   The goal is to bring the negative average log probability down to 0.\n",
        "#\n",
        "#   The term for turning the negative falu is known as cross entropy loss.\n",
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAAYP9PdastS",
        "outputId": "eb5278cc-5165-48e1-f06e-d58f1f759cce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: torch.Size([2, 3, 50257])\n",
            "Targets shape: torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "#   Review the shape of the logits and target tensors:\n",
        "print(\"Logits shape:\", logits.shape)\n",
        "print(\"Targets shape:\", targets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvE34lfNbJYY",
        "outputId": "e57cd63f-8bac-4596-ec93-8933cb1515a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened logits:  torch.Size([6, 50257])\n",
            "Flattened targets:  torch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "#   For the cross_entropy loss function in PyTorch, we want to flatten these\n",
        "# tensors by combining them over the batch dimension:\n",
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "print(\"Flattened logits: \", logits_flat.shape)\n",
        "print(\"Flattened targets: \", targets_flat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFYf_DiGbheC",
        "outputId": "7317adc3-df0f-49e6-e751-a275c4060006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.8009)\n"
          ]
        }
      ],
      "source": [
        "#   Previously, we applied the softmax function, selected the probaility scores\n",
        "# corresponding to the target IDs, and computed the negative average log\n",
        "# probabilities.  PyTorch's cross_entropy function will take care of all the\n",
        "# steps for us:\n",
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-D2DqoqcFMM"
      },
      "source": [
        "### 5.1.3 - Calculating the training and validation set losses\n",
        "\n",
        "  - We must first prepare the training and validation datasets that we will use to train the LLM.\n",
        "  - To compute the loss on the training and validation datasets, we use a very small text dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_Yhb052KcBAK"
      },
      "outputs": [],
      "source": [
        "#   The following code loads \"The Verdict\"\n",
        "import urllib.request\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch02/01_main-chapter-code/the-verdict.txt\")\n",
        "file_path = \"the-verdict.txt\"\n",
        "urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "  text_data = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMVFNVCIfozQ",
        "outputId": "5a79e2ce-d4f6-42f1-8fb8-7099fede3887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 20479\n",
            "Tokens: 5145\n"
          ]
        }
      ],
      "source": [
        "#   Check the number of charaters and tokens in data set\n",
        "total_caracters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "print(\"Characters:\", total_caracters)\n",
        "print(\"Tokens:\", total_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "W9Hq-fHafz17"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt)\n",
        "    for i in range(0, len(token_ids) - max_length, stride):\n",
        "      input_chunk = token_ids[i:i + max_length]\n",
        "      target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle,\n",
        "      drop_last=drop_last,\n",
        "      num_workers=num_workers\n",
        "  )\n",
        "\n",
        "  return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Twwmd51qg6eX"
      },
      "outputs": [],
      "source": [
        "#   Next divide the dataset into a training and validation set and use the data\n",
        "# loaders from chapter 2\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n",
        "\n",
        "#   Usie the train_data and val_data subsets, create respective data loaders\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "  train_data,\n",
        "  batch_size=2,\n",
        "  max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "  stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "  shuffle=True,\n",
        "  drop_last=True,\n",
        "  num_workers=0\n",
        ")\n",
        "val_loader = create_dataloader_v1(\n",
        "  val_data,\n",
        "  batch_size=2,\n",
        "  max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "  stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "  shuffle=True,\n",
        "  drop_last=True,\n",
        "  num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBa2KfqlhitW",
        "outputId": "cd43c944-dcf5-4472-9340-fea86c5bcbb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ],
      "source": [
        "#   We used a relatively small batch size to reduce the computational resource\n",
        "# demand because we were working with a very small dataset.\n",
        "#  Iterate through the data loaders to ensure that they were create correctly:\n",
        "\n",
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "  print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        "  print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6yYNjW9BiFy4"
      },
      "outputs": [],
      "source": [
        "#   Implement a utility function to calculate the cross entropy loss of a given\n",
        "# batch returned via the training and validation loader:\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "  input_batch = input_batch.to(device)\n",
        "  target_batch = target_batch.to(device)\n",
        "  logits = model(input_batch)\n",
        "  loss = torch.nn.functional.cross_entropy(\n",
        "      logits.flatten(0, 1), target_batch.flatten()\n",
        "  )\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lAut4NV6jUh4"
      },
      "outputs": [],
      "source": [
        "#   Function to compute the training and validation loss\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "  total_loss = 0\n",
        "  if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      loss = calc_loss_batch(\n",
        "          input_batch, target_batch, model, device\n",
        "      )\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hr1rapGkEMy",
        "outputId": "6d4d6c57-e426-45a8-910c-48c98576182f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  10.987016677856445\n",
            "Validation loss:  10.980591773986816\n"
          ]
        }
      ],
      "source": [
        "#   Let's see calc_loss_loader function in action\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_loader, model, device)\n",
        "  val_loss = calc_loss_loader(val_loader, model, device)\n",
        "\n",
        "print(\"Training loss: \", train_loss)\n",
        "print(\"Validation loss: \", val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7gopjF2k7yS"
      },
      "source": [
        "  - The loss values are relatively high because the model hasn't been trained.\n",
        "  \n",
        "## 5.2 - Training an LLM\n",
        "\n",
        "  - Time to implement the code for pretraining the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ABBPJcp1k5P9"
      },
      "outputs": [],
      "source": [
        "#   Themain function for pretraining LLMs\n",
        "def train_model_simple(model, train_loader, val_loader,\n",
        "                       optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "  train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "  tokens_seen, global_step = 0, -1\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(\n",
        "          input_batch, target_batch, model, device\n",
        "      )\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      tokens_seen += input_batch.numel()\n",
        "      global_step += 1\n",
        "\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(\n",
        "          model, train_loader, val_loader, device, eval_iter\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:06d})\"\n",
        "              f\"Train loss {train_loss:.3f}, \"\n",
        "              f\"Val loss {val_loss:.3f}\"\n",
        "        )\n",
        "\n",
        "    generate_and_print_sample(\n",
        "      model, tokenizer, device, start_context\n",
        "    )\n",
        "  return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "#   The evaluate_model function calculates the loss over the training and\n",
        "# validation set wwhile ensuring the model is in evaluation mode with gradient\n",
        "# tracking and dropout disabled when calculating the loss over the training\n",
        "# and validation sets:\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(\n",
        "      train_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        "    val_loss = calc_loss_loader(\n",
        "      val_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        "  model.train()\n",
        "  return train_loss, val_loss\n",
        "\n",
        "#   Function used to track whether the model impproves during training.\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "  model.eval()\n",
        "  context_size = model.pos_emb.weight.shape[0]\n",
        "  encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    token_ids = generate_text_simple(\n",
        "      model=model, idx=encoded,\n",
        "      max_new_tokens=50, context_size=context_size\n",
        "    )\n",
        "  decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "  print(decoded_text.replace(\"\\n\", \" \"))\n",
        "  model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc2K0N3czsbq",
        "outputId": "8f2e5e93-efa4-4285-c529-14162c44e28a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000)Train loss 9.764, Val loss 9.903\n",
            "Ep 1 (Step 000005)Train loss 8.077, Val loss 8.339\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Ep 2 (Step 000010)Train loss 6.760, Val loss 7.044\n",
            "Ep 2 (Step 000015)Train loss 6.115, Val loss 6.608\n",
            "Every effort moves you, the,,,,,,,,,,.                                     \n",
            "Ep 3 (Step 000020)Train loss 5.769, Val loss 6.525\n",
            "Ep 3 (Step 000025)Train loss 5.398, Val loss 6.403\n",
            "Every effort moves you.                                                 \n",
            "Ep 4 (Step 000030)Train loss 4.753, Val loss 6.312\n",
            "Ep 4 (Step 000035)Train loss 4.126, Val loss 6.228\n",
            "Every effort moves you, and, and in the picture of the picture, and I had been, and, in the, and, and, and, and of the, and I had been, as of the picture, in the picture--and, and, in\n",
            "Ep 5 (Step 000040)Train loss 4.001, Val loss 6.200\n",
            "Every effort moves you know it was not that, and in the--I had been.                                    \n",
            "Ep 6 (Step 000045)Train loss 3.125, Val loss 6.146\n",
            "Ep 6 (Step 000050)Train loss 2.242, Val loss 6.183\n",
            "Every effort moves you know,\" was one of the Mrs.                                          \n",
            "Ep 7 (Step 000055)Train loss 1.913, Val loss 6.232\n",
            "Ep 7 (Step 000060)Train loss 1.472, Val loss 6.283\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.    \"! The women had been him--it was back the head to look up at the sketch of the donkey.  \"Oh, in\n",
            "Ep 8 (Step 000065)Train loss 1.088, Val loss 6.337\n",
            "Ep 8 (Step 000070)Train loss 0.797, Val loss 6.376\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  He laughed again, and threw back his glory, he had dropped his painting, a _jardiniere_ full of\n",
            "Ep 9 (Step 000075)Train loss 0.501, Val loss 6.416\n",
            "Ep 9 (Step 000080)Train loss 0.307, Val loss 6.482\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
            "Ep 10 (Step 000085)Train loss 0.242, Val loss 6.605\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
          ]
        }
      ],
      "source": [
        "#   Let's see this all in action by training a GPTModel instance for 10 epochs\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(\n",
        "  model.parameters(),\n",
        "  lr = 0.0004, weight_decay = 0.1\n",
        ")\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "o_m87EZK0h12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "3878ab6c-25b4-482b-8881-ee27a6d1cf07"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVwRJREFUeJzt3XdcleX/x/HXYR0Oe8hUwYUIpDhQQ8os+YpmljYs41fasnJnmVppasOGmTnSbGhLbWpWjtwD90AxFU1RHAxRNjLP9fvj6MHjRsFzwM/z8bgfnHPf132fz7mB8z73dS+NUkohhBBCCItkZe4ChBBCCHFlEtRCCCGEBZOgFkIIISyYBLUQQghhwSSohRBCCAsmQS2EEEJYMAlqIYQQwoJJUAshhBAWTIJaCCGEsGAS1ELUAEeOHEGj0RAfH2/uUoQQlUyCWggLodForjqMGTPG3CUKIczAxtwFCCEMUlJSjI9/+uknRo8eTWJionGck5OTOcoSQpiZbFELYSF8fX2Ng6urKxqNxvjc29ubiRMnUqdOHbRaLc2bN2fJkiVXXFZZWRnPPvssTZo0ITk5GYA//viDli1bYm9vT4MGDRg7diylpaXGeTQaDV999RU9evTAwcGBoKAgFi5caJyemZlJbGwsXl5e6HQ6goKCmDVr1hVr+PXXX2natCk6nQ5PT0+io6PJz883Tv/qq68ICQnB3t6eJk2a8Pnnn5vMf+zYMXr27ImbmxseHh489NBDHDlyxDi9T58+dO/enQkTJuDn54enpyf9+/enpKTkute5ENWCEkJYnFmzZilXV1fj84kTJyoXFxc1d+5ctX//fvX6668rW1tbdeDAAaWUUklJSQpQO3fuVIWFhapHjx6qRYsWKj09XSml1Nq1a5WLi4uaPXu2OnTokPrnn39UvXr11JgxY4yvAag6deqoOXPmqIMHD6pBgwYpJycndfr0aaWUUv3791fNmzdXW7duVUlJSWrZsmVq4cKFl63/5MmTysbGRk2cOFElJSWp3bt3q2nTpqnc3FyllFI//PCD8vPzU7/99ps6fPiw+u2335SHh4eaPXu2Ukqp4uJiFRISop599lm1e/dutXfvXvXkk0+q4OBgVVRUpJRSqnfv3srFxUW99NJLat++ferPP/9UDg4OaubMmZX7yxDCzCSohbBAFwe1v7+/eu+990zatG7dWvXr108pVR7U69atUx07dlR33XWXysrKMrbt2LGjev/9903m//7775Wfn5/xOaDeeust4/O8vDwFqMWLFyullOrWrZt65plnrqv+7du3K0AdOXLkstMbNmyo5syZYzLunXfeUZGRkcbagoODlV6vN04vKipSOp1OLV26VCllCOrAwEBVWlpqbPPYY4+pxx9//LpqFKK6kH3UQli4nJwcTp48SVRUlMn4qKgodu3aZTKuV69e1KlTh5UrV6LT6Yzjd+3aRVxcHO+9955xXFlZGYWFhRQUFODg4ABAs2bNjNMdHR1xcXEhPT0dgJdffplHHnmEHTt20KlTJ7p37067du0uW3N4eDgdO3akadOmxMTE0KlTJx599FHc3d3Jz8/n0KFDPPfcc7zwwgvGeUpLS3F1dTXW+99//+Hs7Gyy3MLCQg4dOmR8HhYWhrW1tfG5n58fCQkJV1mbQlQ/EtRC1CD3338/P/zwAxs3buS+++4zjs/Ly2Ps2LE8/PDDl8xjb29vfGxra2syTaPRoNfrAejSpQtHjx5l0aJFLFu2jI4dO9K/f38mTJhwyTKtra1ZtmwZGzZs4J9//mHKlCm8+eabbN682fil4Msvv6Rt27aXzHe+3latWvHjjz9esmwvL6/rqleImkKCWggL5+Ligr+/P3Fxcdxzzz3G8XFxcbRp08ak7csvv8wdd9zBgw8+yN9//21s37JlSxITE2nUqNFN1eLl5UXv3r3p3bs3d999N8OGDbtsUIMhNKOiooiKimL06NEEBgYyf/58hg4dir+/P4cPHyY2Nvay87Zs2ZKffvoJb29vXFxcbqpmIao7CWohqoFhw4bx9ttv07BhQ5o3b86sWbOIj4+/7BbnwIEDKSsr44EHHmDx4sXcddddjB49mgceeICAgAAeffRRrKys2LVrF3v27OHdd9+9rhpGjx5Nq1atCAsLo6ioiL/++ouQkJDLtt28eTMrVqygU6dOeHt7s3nzZk6dOmVsP3bsWAYNGoSrqyudO3emqKiIbdu2kZmZydChQ4mNjeXjjz/moYceYty4cdSpU4ejR4/y+++/8/rrr1OnTp0bX5lCVDMS1EJUA4MGDSI7O5tXX32V9PR0QkNDWbhwIUFBQZdtP2TIEPR6Pffffz9LliwhJiaGv/76i3HjxvHhhx9ia2tLkyZNeP7556+7Bjs7O0aOHMmRI0fQ6XTcfffdzJs377JtXVxcWLt2LZMmTSInJ4fAwEA++eQTunTpAsDzzz+Pg4MDH3/8McOGDcPR0ZGmTZsyZMgQABwcHFi7di3Dhw/n4YcfJjc3l9q1a9OxY0fZwha3HY1SSpm7CCGEEEJcnlzwRAghhLBgEtRCCCGEBZOgFkIIISyYBLUQQghhwSSohRBCCAsmQS2EEEJYMAnqK5g2bRr16tXD3t6etm3bsmXLFnOXZBHWrl1Lt27d8Pf3R6PRsGDBApPpSilGjx6Nn58fOp2O6OhoDh48aNLmzJkzxMbG4uLigpubG8899xx5eXkmbXbv3s3dd9+Nvb09devW5aOPPrqkll9++YUmTZpgb29P06ZNWbRoUaW/31tp/PjxtG7dGmdnZ7y9venevbvJ/ajBcK3r/v374+npiZOTE4888ghpaWkmbZKTk+natSsODg54e3szbNgwk9tZAqxevZqWLVui1Wpp1KgRs2fPvqSemvg/MH36dJo1a4aLiwsuLi5ERkayePFi43RZv5Xrgw8+QKPRGM+PB1nHN8TMNwWxSPPmzVN2dnbqm2++Uf/++6964YUXlJubm0pLSzN3aWa3aNEi9eabb6rff/9dAWr+/Pkm0z/44APl6uqqFixYoHbt2qUefPBBVb9+fXX27Fljm86dO6vw8HC1adMmtW7dOtWoUSPVq1cv4/Ts7Gzl4+OjYmNj1Z49e9TcuXOVTqdTX3zxhbFNXFycsra2Vh999JHau3eveuutt5Stra1KSEio8nVQVWJiYtSsWbPUnj17VHx8vLr//vtVQECAysvLM7Z56aWXVN26ddWKFSvUtm3b1J133qnatWtnnF5aWqruuOMOFR0drXbu3KkWLVqkatWqpUaOHGlsc/jwYeXg4KCGDh2q9u7dq6ZMmaKsra3VkiVLjG1q6v/AwoUL1d9//60OHDigEhMT1RtvvKFsbW3Vnj17lFKyfivTli1bVL169VSzZs3U4MGDjeNlHVecBPVltGnTRvXv39/4vKysTPn7+6vx48ebsSrLc3FQ6/V65evrqz7++GPjuKysLKXVatXcuXOVUkrt3btXAWrr1q3GNosXL1YajUadOHFCKaXU559/rtzd3Y33HVZKqeHDh6vg4GDj8549e6quXbua1NO2bVv14osvVup7NKf09HQFqDVr1iilDOvS1tZW/fLLL8Y2+/btU4DauHGjUsrwRcrKykqlpqYa20yfPl25uLgY1+frr7+uwsLCTF7r8ccfVzExMcbnt9P/gLu7u/rqq69k/Vai3NxcFRQUpJYtW6buueceY1DLOr4x0vV9keLiYrZv3050dLRxnJWVFdHR0WzcuNGMlVm+pKQkUlNTTdadq6srbdu2Na67jRs34ubmRkREhLFNdHQ0VlZWbN682dimffv22NnZGdvExMSQmJhIZmamsc2Fr3O+TU36HWVnZwPg4eEBwPbt2ykpKTF5302aNCEgIMBk/TZt2hQfHx9jm5iYGHJycvj333+Nba627m6X/4GysjLmzZtHfn4+kZGRsn4rUf/+/enatesl60HW8Y2Ra31fJCMjg7KyMpM/EgAfHx/2799vpqqqh9TUVIDLrrvz01JTU/H29jaZbmNjg4eHh0mb+vXrX7KM89Pc3d1JTU296utUd3q9niFDhhAVFcUdd9wBGN67nZ0dbm5uJm0vXr+XWy/np12tTU5ODmfPniUzM7NG/w8kJCQQGRlJYWEhTk5OzJ8/n9DQUOLj42X9VoJ58+axY8cOtm7desk0+Ru+MRLUQlig/v37s2fPHtavX2/uUmqc4OBg4uPjyc7O5tdff6V3796sWbPG3GXVCMeOHWPw4MEsW7bM5D7n4uZI1/dFatWqhbW19SVHIaalpeHr62umqqqH8+vnauvO19eX9PR0k+mlpaWcOXPGpM3llnHha1ypTU34HQ0YMIC//vqLVatWmdzO0dfXl+LiYrKyskzaX7x+b3Tdubi4oNPpavz/gJ2dHY0aNaJVq1aMHz+e8PBwPvvsM1m/lWD79u2kp6fTsmVLbGxssLGxYc2aNUyePBkbGxt8fHxkHd8ACeqL2NnZ0apVK1asWGEcp9frWbFiBZGRkWaszPLVr18fX19fk3WXk5PD5s2bjesuMjKSrKwstm/fbmyzcuVK9Ho9bdu2NbZZu3YtJSUlxjbLli0jODgYd3d3Y5sLX+d8m+r8O1JKMWDAAObPn8/KlSsv6f5v1aoVtra2Ju87MTGR5ORkk/WbkJBg8mVo2bJluLi4EBoaamxztXV3u/0P6PV6ioqKZP1Wgo4dO5KQkEB8fLxxiIiIIDY21vhY1vENMPfRbJZo3rx5SqvVqtmzZ6u9e/eqvn37Kjc3N5OjEG9Xubm5aufOnWrnzp0KUBMnTlQ7d+5UR48eVUoZTs9yc3NTf/zxh9q9e7d66KGHLnt6VosWLdTmzZvV+vXrVVBQkMnpWVlZWcrHx0c99dRTas+ePWrevHnKwcHhktOzbGxs1IQJE9S+ffvU22+/Xe1Pz3r55ZeVq6urWr16tUpJSTEOBQUFxjYvvfSSCggIUCtXrlTbtm1TkZGRKjIy0jj9/KktnTp1UvHx8WrJkiXKy8vrsqe2DBs2TO3bt09Nmzbtsqe21MT/gREjRqg1a9aopKQktXv3bjVixAil0WjUP//8o5SS9VsVLjzqWylZxzdCgvoKpkyZogICApSdnZ1q06aN2rRpk7lLsgirVq1SwCVD7969lVKGU7RGjRqlfHx8lFarVR07dlSJiYkmyzh9+rTq1auXcnJyUi4uLuqZZ55Rubm5Jm127dql7rrrLqXValXt2rXVBx98cEktP//8s2rcuLGys7NTYWFh6u+//66y930rXG69AmrWrFnGNmfPnlX9+vVT7u7uysHBQfXo0UOlpKSYLOfIkSOqS5cuSqfTqVq1aqlXX31VlZSUmLRZtWqVat68ubKzs1MNGjQweY3zauL/wLPPPqsCAwOVnZ2d8vLyUh07djSGtFKyfqvCxUEt67jiNEopZZ5teSGEEEJci+yjFkIIISyYBLUQQghhwSSohRBCCAsmQS2EEEJYMAlqIYQQwoJJUAshhBAWTIL6KoqKihgzZgxFRUXmLqVGkvVbtWT9Vj1Zx1VL1q+BnEd9FTk5Obi6upKdnY2Li4u5y6lxZP1WLVm/VU/WcdWS9WsgW9RCCCGEBZOgFkIIISxYjb8fdWlpKTt37sTHxwcrq4p9L8nNzQXgxIkT5OTkVEV5tzVZv1VL1m/Vk3VctWry+tXr9aSlpdGiRQtsbK4exTV+H/XWrVtp06aNucsQQgghLrFlyxZat2591TY1fovax8cHMKwMPz8/M1cjhBBCQEpKCm3atDFm1NXU+KA+393t5+dHnTp1zFyNEEIIUe56dsma9WCytWvX0q1bN/z9/dFoNCxYsMBkulKK0aNH4+fnh06nIzo6moMHD5qnWCGEEMIMzBrU+fn5hIeHM23atMtO/+ijj5g8eTIzZsxg8+bNODo6EhMTQ2Fh4S2uVAghhDAPs3Z9d+nShS5dulx2mlKKSZMm8dZbb/HQQw8B8N133+Hj48OCBQt44oknbmWpQgghhFlY7D7qpKQkUlNTiY6ONo5zdXWlbdu2bNy48YpBXVRUZHK5ufOH9wshxPUoKyujpKTE3GWIas7W1hZra+tKWZbFBnVqairAJUfE+fj4GKddzvjx4xk7dmyV1iaEqHmUUqSmppKVlWXuUkQN4ebmhq+vLxqN5qaWY7FBfaNGjhzJ0KFDjc9PnDhBaGho5Sy8rBSWvw3174HGnSpnmUIIi3A+pL29vXFwcLjpD1dx+1JKUVBQQHp6OsBNnxpssUHt6+sLQFpamsmbTEtLo3nz5lecT6vVotVqjc8r82o2autXaDZOhR3fwfPLwSu40pYthDCfsrIyY0h7enqauxxRA+h0OgDS09Px9va+qW5wi73Wd/369fH19WXFihXGcTk5OWzevJnIyMhbXk9BcSmvH2lFvFUYFOXAnMeh4Mwtr0MIUfnO75N2cHAwcyWiJjn/93SzxzyYNajz8vKIj48nPj4eMBxAFh8fT3JyMhqNhiFDhvDuu++ycOFCEhISePrpp/H396d79+63vNbiUj0bjuTybMFAMmx8ITMJfukDZXLQiRA1hXR3i8pUWX9PZg3qbdu20aJFC1q0aAHA0KFDadGiBaNHjwbg9ddfZ+DAgfTt25fWrVuTl5fHkiVLsLe3v+W1ujnYMS22JbnWrvxf/hBKrHWQtAaWvnHLaxFCCHH7MGtQd+jQAaXUJcPs2bMBw7eRcePGkZqaSmFhIcuXL6dx48Zmq7d5XTdGPRDKfhXAwMKXDSO3zIRts8xWkxBCVLZ69eoxadKk626/evVqNBpNlR8xP3v2bNzc3Kr0NSyRxe6jtlRP3RlIt3B/lpRFMMP6ScPIRa/BkfXmLUwIcdvRaDRXHcaMGXNDy926dSt9+/a97vbt2rUjJSUFV1fXG3o9cXUWe9S3pdJoNIx/uCn/nszmg1NdCfc4SWTBavjpKei7CtzrmbtEIcRtIiUlxfj4p59+YvTo0SQmJhrHOTk5GR8rpSgrK7vmvY8BvLy8KlSHnZ2d8UwdUflki/oGOGltmPF/rdDZ2vDMmd6kOYXA2TMwtxcUyZXQhBC3hq+vr3FwdXVFo9EYn+/fvx9nZ2cWL15Mq1at0Gq1rF+/nkOHDvHQQw/h4+ODk5MTrVu3Zvny5SbLvbjrW6PR8NVXX9GjRw8cHBwICgpi4cKFxukXd32f76JeunQpISEhODk50blzZ5MvFqWlpQwaNAg3Nzc8PT0ZPnw4vXv3rvDBwtOnT6dhw4bY2dkRHBzM999/b5ymlGLMmDEEBASg1Wrx9/dn0KBBxumff/45QUFB2Nvb4+Pjw6OPPlqh175VJKhvUGMfZ97rcQeFaHnodH+K7L0gfS/8/iLo9eYuTwhxk5RSFBSXmmVQSlXa+xgxYgQffPAB+/bto1mzZuTl5XH//fezYsUKdu7cSefOnenWrRvJyclXXc7YsWPp2bMnu3fv5v777yc2NpYzZ658impBQQETJkzg+++/Z+3atSQnJ/Paa68Zp3/44Yf8+OOPzJo1i7i4OHJyci65g+K1zJ8/n8GDB/Pqq6+yZ88eXnzxRZ555hlWrVoFwG+//cann37KF198wcGDB1mwYAFNmzYFDAczDxo0iHHjxpGYmMiSJUto3759hV7/VpGu75vwcMs6bD2Sydwt8ELxK3xrPRbN4VVwaj/4VNLV0IQQZnG2pIzQ0UvN8tp7x8XgYFc5H8/jxo3jf//7n/G5h4cH4eHhxufvvPMO8+fPZ+HChQwYMOCKy+nTpw+9evUC4P3332fy5Mls2bKFzp07X7Z9SUkJM2bMoGHDhgAMGDCAcePGGadPmTKFkSNH0qNHDwCmTp3KokWLKvTeJkyYQJ8+fejXrx9gOHNo06ZNTJgwgXvvvZfk5GR8fX2Jjo7G1taWgIAA2rRpA0BycjKOjo488MADODs7ExgYaDwDydLIFvVNertbKGH+LqwtqMfHjq9S0meJhLQQwmJERESYPM/Ly+O1114jJCQENzc3nJyc2Ldv3zW3qJs1a2Z87OjoiIuLi/ESmZfj4OBgDGkwXEbzfPvs7GzS0tKMoQlgbW1Nq1atKvTe9u3bR1RUlMm4qKgo9u3bB8Bjjz3G2bNnadCgAS+88ALz58+ntLQUgP/9738EBgbSoEEDnnrqKX788UcKCgoq9Pq3imxR3yR7W2umx7ai65R1fJ5+B0U7bRlV+9xEpUAuoCBEtaSztWbvuBizvXZlcXR0NHn+2muvsWzZMiZMmECjRo3Q6XQ8+uijFBcXX3U5tra2Js81Gg36q+zmu1z7yuzSvx5169YlMTGR5cuXs2zZMvr168fHH3/MmjVrcHZ2ZseOHaxevZp//vmH0aNHM2bMGLZu3Wpxp4DJFnUlCPB0YGLP5gB8vT6JxQkpkLwZZt4DOSlXn1kIYZE0Gg0OdjZmGaryCmlxcXH06dOHHj160LRpU3x9fTly5EiVvd7luLq64uPjw9atW43jysrK2LFjR4WWExISQlxcnMm4uLg4kxsx6XQ6unXrxuTJk1m9ejUbN24kISEBABsbG6Kjo/noo4/YvXs3R44cYeXKlTfxzqqGbFFXkv+F+vBi+wZ8sfYwr/8az33e76E9lQAr34Xu08xdnhBCABAUFMTvv/9Ot27d0Gg0jBo16qpbxlVl4MCBjB8/nkaNGtGkSROmTJlCZmZmhb6kDBs2jJ49e9KiRQuio6P5888/+f33341Hsc+ePZuysjLatm2Lg4MDP/zwAzqdjsDAQP766y8OHz5M+/btcXd3Z9GiRej1eoKDLe9mS7JFXYleiwmmTT0Pcov0vFg4iNJmT0KXD81dlhBCGE2cOBF3d3fatWtHt27diImJoWXLlre8juHDh9OrVy+efvppIiMjcXJyIiYmpkKXiO7evTufffYZEyZMICwsjC+++IJZs2bRoUMHwHA/6C+//JKoqCiaNWvG8uXL+fPPP/H09MTNzY3ff/+d++67j5CQEGbMmMHcuXMJCwurond84zTqVu80uMWOHz9O3bp1OXbsGHXq1Kny10vLKaTr5HVk5BXTM6IOHz0afu2ZhBBmVVhYSFJSEvXr1zfLvQQE6PV6QkJC6NmzJ++88465y6kUV/u7qkg2yRZ1JfNxsWfyEy2w0sDP247z89ZjhoPK1k6AxMXmLk8IISzC0aNH+fLLLzlw4AAJCQm8/PLLJCUl8eSTT5q7NIsjQV0F2jWqxdD/GW4eMuqPPZxY/TWsfAd+ex7S95m5OiGEMD8rKytmz55N69atiYqKIiEhgeXLlxMSEmLu0iyOHExWRfp1aMS2o5msTjzF01sDWRpwFzbJ62HuE/D8SnD0NHeJQghhNnXr1r3kiG1xebJFXUWsrDR82rM5td10HDpTzAjrV1Hu9SDzCPzSG8pKzF2iEEKIakCCugq5O9oxLbYlttYaft13lt+DJ4CdMxxZB4tfN3d5QgghqgEJ6irWvK4bb3U1nHw/fG0J/7X/FNDAtm9gy5fmLU4IIYTFk6C+BZ6ODOSBZn6U6hVPrfMg/+43DRMWD4fDa8xbnBBCCIsmQX0LaDQaPnikGQ28HEnJLuSlpLvRN+0Jqsywv/rMYXOXKIQQwkJJUN8iTlobpse2wt7WinX/nWaa8yCo3QrOZsKcJ6Awx9wlCiGEsEAS1LdQsK8z7/cw3LR84qpkNrWZAs5+kJFoOMdaX2bmCoUQt6MOHTowZMgQ4/N69eoxadKkq86j0WhYsGDBTb92ZS3nasaMGUPz5s2r9DWqkgT1LfZwyzr0ahOAUtBv4UkyHpgFNvZwaCWc3Gnu8oQQ1Ui3bt3o3LnzZaetW7cOjUbD7t27K7zcrVu30rdv35stz8SVwjIlJYUuXbpU6mvVNBLUZvB2t1DC/F04k19M3xV6Srt/Ab0XQp2Ia88shBDnPPfccyxbtozjx49fMm3WrFlERETQrFmzCi/Xy8sLBweHyijxmnx9fdFqtbfktaorCWozsLe15vPYljjb27AjOYvxRxpDYLvyBvkZhuuDCyHEVTzwwAN4eXkxe/Zsk/F5eXn88ssvPPfcc5w+fZpevXpRu3ZtHBwcaNq0KXPnzr3qci/u+j548CDt27fH3t6e0NBQli1bdsk8w4cPp3Hjxjg4ONCgQQNGjRpFSYnhwk6zZ89m7Nix7Nq1C41Gg0ajMdZ8cdd3QkIC9913HzqdDk9PT/r27UteXp5xep8+fejevTsTJkzAz88PT09P+vfvb3yt66HX6xk3bhx16tRBq9XSvHlzlixZYpxeXFzMgAED8PPzw97ensDAQMaPHw+AUooxY8YQEBCAVqvF39+fQYMGXfdr3wiLDuqysjJGjRpF/fr10el0NGzYkHfeeYeacMOvQE9HPnnMcGetr9cnsTghxTAh4yBMj4IV4ySshbAExfkVH8pKy+cvKzWMKzl7fcutABsbG55++mlmz55t8rn4yy+/UFZWRq9evSgsLKRVq1b8/fff7Nmzh759+/LUU0+xZcuW63oNvV7Pww8/jJ2dHZs3b2bGjBkMHz78knbOzs7Mnj2bvXv38tlnn/Hll1/y6aefAvD444/z6quvEhYWRkpKCikpKTz++OOXLCM/P5+YmBjc3d3ZunUrv/zyC8uXL2fAgAEm7VatWsWhQ4dYtWoV3377LbNnz77ky8rVfPbZZ3zyySdMmDCB3bt3ExMTw4MPPsjBgwcBmDx5MgsXLuTnn38mMTGRH3/8kXr16gHw22+/8emnn/LFF19w8OBBFixYQNOmTa/7tW+ERV/r+8MPP2T69Ol8++23hIWFsW3bNp555hlcXV2r/BvMrdApzJe+7Rswc+1hXv91N038XKh/dAPkpcKBJXD3q6B1MneZQtze3vev+DyPzYawHobH+/+EX/pA4F3wzN/lbSY1hYLTl847JrtCL/Xss8/y8ccfs2bNGuN9mGfNmsUjjzyCq6srrq6uvPbaa8b2AwcOZOnSpfz888+0adPmmstfvnw5+/fvZ+nSpfj7G9bF+++/f8l+5bfeesv4uF69erz22mvMmzeP119/HZ1Oh5OTEzY2Nvj6+l7xtebMmUNhYSHfffcdjo6OAEydOpVu3brx4Ycf4uPjA4C7uztTp07F2tqaJk2a0LVrV1asWMELL7xwXetswoQJDB8+nCeeeAIwZM2qVauYNGkS06ZNIzk5maCgIO666y40Gg2BgYHGeZOTk/H19SU6OhpbW1sCAgKuaz3eDIveot6wYQMPPfQQXbt2pV69ejz66KN06tTpur8JVgfDYoJpXc+d3KJSnvt2K+mNH4ceX0DvPyWkhRDX1KRJE9q1a8c333wDwH///ce6det47rnnAEPP5DvvvEPTpk3x8PDAycmJpUuXkpycfF3L37dvH3Xr1jWGNEBkZOQl7X766SeioqLw9fXFycmJt95667pf48LXCg8PN4Y0QFRUFHq9nsTEROO4sLAwrK2tjc/9/PxIT0+/rtfIycnh5MmTREVFmYyPiopi3z7D3Q379OlDfHw8wcHBDBo0iH/++cfY7rHHHuPs2bM0aNCAF154gfnz51NaWkpVsugt6nbt2jFz5kwOHDhA48aN2bVrF+vXr2fixIlXnKeoqIiioiLj89zc3FtR6g2ztbZi6pMt6TEtjsOn8on9cjPz+vbA0/GCgytO7gS/5qDRmK1OIW5bb5ys+DzWF/z/NulmWIbmou2iIQk3V9cFnnvuOQYOHMi0adOYNWsWDRs25J577gHg448/5rPPPmPSpEk0bdoUR0dHhgwZQnFxcaW9/saNG4mNjWXs2LHExMTg6urKvHnz+OSTTyrtNS5ka2tr8lyj0aDX6ytt+S1btiQpKYnFixezfPlyevbsSXR0NL/++it169YlMTGR5cuXs2zZMvr162fs0bi4rspi0VvUI0aM4IknnqBJkybY2trSokULhgwZQmxs7BXnGT9+vLG7x9XVldDQ0FtY8Y3xcbFnbt878XWx52B6HrFfbSYz/9w/0fbZMLMDrHpf9lkLYQ52jhUfrC/YBrK2MYyz1V3fcm9Az549sbKyYs6cOXz33Xc8++yzaM59sY+Li+Ohhx7i//7v/wgPD6dBgwYcOHDgupcdEhLCsWPHSElJMY7btGmTSZsNGzYQGBjIm2++SUREBEFBQRw9etT07drZUVZ29WtFhISEsGvXLvLzy/fVx8XFYWVlRXBw8HXXfDUuLi74+/tfcovNuLg4k7xwcXHh8ccf58svv+Snn37it99+48yZMwDodDq6devG5MmTWb16NRs3biQhofK+eF3MooP6559/5scff2TOnDns2LGDb7/9lgkTJvDtt99ecZ6RI0eSnZ1tHPbu3XsLK75xgZ6OzHmhLV7OWvan5vJ/X28mu6AEigsMDdZ+BKvHm7dIIYRFcnJy4vHHH2fkyJGkpKTQp08f47SgoCCWLVvGhg0b2LdvHy+++CJpaWnXvezo6GgaN25M79692bVrF+vWrePNN980aRMUFERycjLz5s3j0KFDTJ48mfnz55u0qVevHklJScTHx5ORkWHS83lebGws9vb29O7dmz179rBq1SoGDhzIU089Zdw/XRmGDRvGhx9+yE8//URiYiIjRowgPj6ewYMHAzBx4kTmzp3L/v37OXDgAL/88gu+vr64ubkxe/Zsvv76a/bs2cPhw4f54Ycf0Ol0JvuxK5tFB/WwYcOMW9VNmzblqaee4pVXXjEeJn85Wq0WFxcX4+Ds7HwLK745DbycmPtCW2o52fHvyRye+mYzOS1egE7vGRqs+RBWSVgLIS713HPPkZmZSUxMjMn+5LfeeouWLVsSExNDhw4d8PX1pXv37te9XCsrK+bPn8/Zs2dp06YNzz//PO+9955JmwcffJBXXnmFAQMG0Lx5czZs2MCoUaNM2jzyyCN07tyZe++9Fy8vr8ueIubg4MDSpUs5c+YMrVu35tFHH6Vjx45MnTq1YivjGgYNGsTQoUN59dVXadq0KUuWLGHhwoUEBQUBhiPYP/roIyIiImjdujVHjhxh0aJFWFlZ4ebmxpdffklUVBTNmjVj+fLl/Pnnn3h6elZqjRfSKAs+18nT05N3332Xl19+2Thu/PjxzJo167q7bo4fP07dunU5duwYderUqapSK1Viai5PzNxIZkEJLQLc+O7ZNjjvmAH/nDuqssNI6DDCvEUKUYMUFhaSlJRE/fr1sbe3N3c5ooa42t9VRbLJoreou3Xrxnvvvcfff//NkSNHmD9/PhMnTqRHjx7mLq1KBfs688PzbXHV2bIzOYtnZm0lv9XL8L93DA1Wj4fVH5q3SCGEELeERQf1lClTePTRR+nXrx8hISG89tprvPjii7zzzjvmLq3Khfm78sNzbXG2t2Hb0Uyenb2Vs637w//GGRqsfh/WfGTeIoUQQlQ5iw5qZ2dnJk2axNGjRzl79iyHDh3i3Xffxc7Oztyl3RJN67jy/XNtcdLasDnpDM9/t5XCNgMgeqyhwar3YM3H5i1SCCFElbLooBbQvK4b3z7bGkc7a+L+O03f77dT2HYgRI8xNFj1LqyVsBZCiJpKgroaaBXowaxn2qCztWbtgVP0+3EHxXcOho5vGxqsfBfWTjBvkUIIIaqEBHU10aa+B1/3iUBrY8XK/ekMmLODknZDoONoc5cmRI1RmVe3EqKy/p4s+hKiwlS7hrX4qncEz327jX/2pjF43k4mP/EKNoF3QUBbc5cnRLVlZ2eHlZUVJ0+exMvLCzs7O+OVvYSoKKUUxcXFnDp1Cisrq5s+rkqCupq5O8iLL55qxYvfbWdRQio2Vrv49PE2GC9PX5QL+xdB+KW3kBNCXJ6VlRX169cnJSWFkydv4NreQlyGg4MDAQEBWFndXOe1BHU1dG+wN5/HtuSlH7azcNdJbKw0fPxYONb6EvjhUTi2Cc6egTtfvvbChBCAYas6ICCA0tLSa16TWohrsba2xsbGplJ6ZiSoq6noUB+mPtmC/nN28vvOE9hYa/jg4WZYNeoIp/ZBwJ3mLlGIakej0WBra1tld0ES4kbIwWTVWOc7/PjsieZYaeDnbcd56489qPbDoP8W8G9h7vKEEEJUAgnqau6BZv5M7NkcjQbmbE7m7YX/opwuuMvM8W2w+QvzFSiEEOKmSNd3DdC9RW1K9Yphv+7iu41HsbGyYtQDIWhyTsL3PaAoB3Z+D2E9IOxh8Khv7pKFEEJcJ9miriEebVWH8T2aAvBNXBIfLNmPcvGHqEFgZQOpCbBiHExuDjM7QNxnkJVs1pqFEEJcm2xR1yBPtAmgRK8YtWAPX6w5jJ21Fa92GgYRz8G+hfDvfEhaCyd3GoZlo6F2BNzxMIR2B9fa5n4LQgghLiJBXcM8dWcgZWV6xvy5lykr/8PGyorB0UHQqo9hyDtVHtpH1sOJbYZh6RtQ905DaLfpC3KxByGEsAgS1DVQn6j6lOoV7/69j0+XH8DGWkP/exsZJjp5QevnDENuKuxdCP/+DskbDedflxVD2xfLF1aUC1pn87wRIYQQEtQ11fN3N6C4TM9HSxL5eGkiW4+cYUh0Y5rXdStv5OwLbfsahuwTsPcPcPIun342CyaGQJ3W8MSPEthCCGEGEtQ1WL8Ohq3oT/45wOrEU6xOPMW9wV4MvjiwwbB/OrKf6bijG6CkAPLSTEM6aS34NgWde9W+ASGEEGiUUsrcRVSl48ePU7duXY4dO0adOnXMXY5ZHMnIZ8rK/1gQf4IyveHXfcXAvtiZJENQn7/SWXEBfNzI0EXe8F6od7chsHVuYO8K9ud/uoLWBW7yGrdCCGE2JYWGz7/zg60DNOpYKYuuSDZJUN9Gbiqwzzt1AH7pA+n/XkdjDdi7GML7/36DWkGG0QeWGrbK690NwZ0N48pK4MSO8pDXuYGtrmJvUAghrkUpw3B+I+LEdsOBtblppqGcmwZF2abzBrSDZxdXShkVySbp+r6N1KvlyCc9wxl4XyNjYK9KPMWqq3WJX8yrMfTbAKcS4d8FcPogFGYb9mcXZp8bsqC0EFDl42y05cs4sg42TjU8Ph/UeWnwTSfT17JzAiefc4N3+U9n3/LHtRpLoAtxu1IKSs5CcZ7hwNfzP89mGT5TbOyhRWx5+y/aQ9pe6LvKsPsO4PAaWDH2yq9hrQXnc59DPmFV+nauRIL6NlQ5gR0MHYZfeXpJ4QXBnQ1OvhcU0N7wM/Cu8nGlReBe3xDyhdmg9IZ/ujN5cObQlV+n7xrwb254HD8HEn6FkG4Q8YxhXFmp4Yh2Z19DsGtd5NQzIcylrMTwJb606FzA5huC1dq2/P8YYOPnkJ8ObV82hCTAzh9h2zflYVyUZ3isrnKns1qNTYNarwd9iWFr+XxQ+zeHZo+f2xg4txFwPpidfAw9fGb+zJCgvo1dLbDva+LN4I5BhF9vl/jFbO0Ng7PPpdMadzIMF/JsCIPjDY+VMlz2ND/DcApZXhrkpV/w84JxF17XPHUPHFph+q03LxW+faD8uY09OHobutZ17uDgcW4f+0VDvbsM/6Dn65FwF9Xd+b2c5/+W80/D2UxDcJYVGcKztBBKi8+NKy4P1dJCw+AWCM16li9zQX/D/+oDn4JjLcO4DVNh5w8XzXvu55VCtXYEvLCi/PnGaZBz3PCl+/xnSP4pwzUfrsTOyTBonQ3/u04+l14u+bFZhh64Cz83Gt5nGCyYBLW4bGCv3J/Oyv3pNx/YN0KjKd9X7dnw+ucLf8IQ0l5NyscVF4BnkCHYi3IMHxbZyYbhal7eUB7U6ybAuk+h9bPQ6d1zy803XCTm4oC3dzM9sE7rLCEvrk9ZKWQdNfyNXvhl8/AaOHPYcAZGcQGU5JdvjRrHFVwQrMUQFA3/G2eYv+QsfBBgmD7yePkZHMtGQ/wPFaux4X2mQb1voeH/KnpMeVAXnDbcavdarLVg5whaJ0OP14Wa9zJsMes8ysc1ecBwnIudk2EerUv5Y1vH6ztw9fxxMtWMBLUwsrjArii/ZobhQl6NYeC5b+HFBYbutLxThi72gjOGLYrLDQ61ypdxNsvw4cgFgVtwGrbPvnZNGqvy0Na5wUPTyj+EkzfD0ThD19v5b/RKGT6Uzx89by3/omZVVmIIQSsbQ6iAISBP7DBsHTboUN529y+QmWRoX3L2gp/nQ/XsBSF7LnBbPl3+5S//FExpCRprGH26/Avelpmw/6+K1e3VuPyxtdYQ0mAI8fOHi2idQetqOH7Exh5s7Aw/rc/9tNFeMJx77h1q+jrRbxv+Zh0uCNQW/2c4I8S4jIt/6gyvcbVgve+tS8fVamQYbkPyKSAuUe0D+0rsHMCuHrjXq9h8HUYYruRm61g+ztYROrxxUcCfueDAuizDh6PSl0/PvGi5SWth1buGD+vzQV2UY/iwNtbsdC60XQwfcla2hg85a5tzH3a2hv17HUaAd4hhnqMbYd+fhi8t4U+UL2vjNEPgWNuazmujNXQH2joa1pHtucHOwfD6VtYVW1+3QlnppYFYehac/cHFz9AmNw0S/zYEQ/Ne5fOuGg+ZRwzzlRZeFKoXhGtJAehLDfPcMxzufcPwOPu4YXeKzgOGJ5Uvd8e3hgMlK6LwgqOK7RzAztnws6zEEJwAtVsZ/o7O/04u93uydSgPQ2s7cPYrX66VFQzZY5h24bUPunxgGG5G6+cvHefZsGI9YeKaLD6oT5w4wfDhw1m8eDEFBQU0atSIWbNmERERYe7SarwaG9gVpXW+9Kpsjp5XP5ju/NGo54+CP39UvFtgeRufUAh/EgIiy8cV5RnCsTjP8Lz43AEzOdeo8cLLvqbsgk3TDLc0PR/U+jJDV31FPTrLcP13MJxWt/QNwzn1D00rb/P3q4ZAs3U0BP75MLHVGQKmrPjcPsqi8n2hYT2g9rkvJCe2w7qJhi9QMe+VL/fbByHnhGEr0LgP9dwylP7y9ca8D5H9DY+zjsJfrxiWe2FQJy6C1N0VWw8lBeWPtc6G3SsXX/CncYwhoM4HqK3uop/2F4TsuS9GDp7l89u7whvHL33tu4dWrNbLcat788sQZmPRQZ2ZmUlUVBT33nsvixcvxsvLi4MHD+LuLlfEupWuFtht63vQIdibu4NqEerngpWV7I8FDN2Wdue2dlz8Lt+mSVfDcCHX2vDGCcMW4/mQL8yCwhxD4JWVlP/UX/DYo0H5MvybQ9QQ0/2cSg9Ne56b54L5zh+FW1Jwwf7Oc120Sl/e3QuG7v7T/13aIxE/99yugQqo1bg8qPNPG7p2/cJN22QeMYTtVWlMw9DGvnySYy3Dfs2L93+2fdGw28MkQC9aht25Lxrnx1nblc/v4g/9N19aSruB1/vuhagQi77gyYgRI4iLi2Pdugp2J11ALnhS+S534RQAdwdb2jWqxd2NahHVqBZ1PRzMWKW4KUoZtl6tbMr3k+edMpw3b+doGqobPzds9V9ysFOBYR+9jZ1hP+mF+0DDekCdc71i2ccNW+tOPhBywRH6yZsN+4HPz2vyU1ve3SsH64lqqMZcmSw0NJSYmBiOHz/OmjVrqF27Nv369eOFF1644jxFRUUUFRUZn584cYLQ0FAJ6ipw7EwBK/alsf6/DDYdPkNeUanJ9HqeDtwVVIu7GtUismEtXHW2ZqpUCCEsS40Jant7QzfW0KFDeeyxx9i6dSuDBw9mxowZ9O7d+7LzjBkzhrFjL73KjAR11Sop07PrWBbrDmYQ918GO49lmWxtW2mgWR037mpUi7uCatEywB07G7kOuBDi9lRjgtrOzo6IiAg2bNhgHDdo0CC2bt3Kxo0bLzuPbFFbhtzCEjYdPkPcfxmsO3iKQ6dM92HqbK1p28DDGNzBPs5opAtTCHGbqDHX+vbz8yM01PS8vZCQEH777bcrzqPVatFqy68rnZNzrcNlRVVwtrflf6E+/C/UcAWgk1lnifsvg/X/Gba4M/KKjbfeBPBy1hpC+1xw+7jYX23xQghx27DooI6KiiIxMdFk3IEDBwgMDLzCHMJS+bvpeCyiLo9F1EWvVySm5bL+YAbr/stgS9JpTuUWMX/nCebvPAFAkLcT7Rt7cW+wN63ru6O1scBzeYUQ4haw6KB+5ZVXaNeuHe+//z49e/Zky5YtzJw5k5kzZ5q7NHETrKw0hPi5EOLnwgvtG1BUWsb2o5msP7d/e/eJbA6m53EwPY+v1yfhYGdNu4a1uLeJFx2CvantJnfLEkLcPm5oH/WxY8fQaDTGfvUtW7YwZ84cQkND6du3b6UW+NdffzFy5EgOHjxI/fr1GTp06FWP+r6YnJ5V/WQVFBP332lWJ6az+sApTuUWmUxv7OPEvcHe3BPsRUSghxyUJoSodqr8YLK7776bvn378tRTT5GamkpwcDBhYWEcPHiQgQMHMnr06BsuvrJJUFdver1ib0oOaw6cYtX+dHYkZ3LBweQ4aW24q1EtOgQbtrZ9XWXfthDC8lV5ULu7u7Np0yaCg4OZPHkyP/30E3Fxcfzzzz+89NJLHD58+IaLr2wS1DVLVkEx6w5msCoxnbUHTpGRV2wyvYmvM/c28ebeYG9aBrhhYy1b20IIy1PlR32XlJQYj6xevnw5Dz74IABNmjQhJSXlRhYpxHVxc7CjW7g/3cL90esVe05ms2r/KVYfSCf+WBb7U3PZn5rL9NWHcLa3oX2QF/cEe9GhsRfeciS5EKIauqGgDgsLY8aMGXTt2pVly5bxzjvvAHDy5Ek8PT2vMbcQlcPKSkOzOm40q+PG4OggzuQXs+6goYt87cEMzuQX83dCCn8nGL48hvm7cG+wNx1DvGle103O2xZCVAs31PW9evVqevToQU5ODr179+abb74B4I033mD//v38/vvvlV7ojZKu79tTmV6x+3jWuXO109l1PNtkept6HgyJDiKyoacEthDilrslVyYrKysjJyfH5E5WR44cwcHBAW9v7xtZZJWQoBYAGXlFrD1wipX70/lnbxrFpYbbJEpgCyHMocqD+uzZsyilcHAw3B3p6NGjzJ8/n5CQEGJiYm6s6ioiQS0ulppdyIw1h5izJVkCWwhhFhXJphs6JPahhx7iu+++AyArK4u2bdvyySef0L17d6ZPn34jixTilvF1tWfMg2GsHXYvfdrVw87Gii1HzvDkV5t5fOYmNhzKwIIvgS+EuM3cUFDv2LGDu+++G4Bff/0VHx8fjh49ynfffcfkyZMrtUAhqsplAzvpDE9+KYEthLAcNxTUBQUFODs7A/DPP//w8MMPY2VlxZ133snRo0crtUAhqtqFgd07MhA7awlsIYTluKGgbtSoEQsWLODYsWMsXbqUTp06AZCeno6Li0ulFijEreLras/Yh+5g7etXDmwhhLjVbiioR48ezWuvvUa9evVo06YNkZGRgGHrukWLFpVaoBC32vnAXvN6h0sD+4uNbDx02twlCiFuIzd8elZqaiopKSmEh4djZWXI+y1btuDi4kKTJk0qtcibIUd9i5uVkn2WGasPMXfLMYrLDEeJt63vwZDoxkQ2lAv8CCEq7pacR33hiwEWG4IS1KKypGSfZfrqQ8yTwBZC3KQqPz1Lr9czbtw4XF1dCQwMJDAwEDc3N9555x30ev0NFS2EpfNz1THuXJf40+e6xDcnnaHXl5ukS1wIUWVu6Frfb775Jl9//TUffPABUVFRAKxfv54xY8ZQWFjIe++9V6lFCmFJzgf2yx0aGrewzwd2m/oeDLoviKhGcuEUIUTluKGub39/f2bMmGG8a9Z5f/zxB/369ePEiROVVuDNkq5vUdUu1yXeIsCNgfc14t5gbwlsIcQlqrzr+8yZM5c9YKxJkyacOXPmRhYpRLV1YZd4n3b10NpYsTM5i2dnb+OBKetZsicFvV7OwxZC3JgbCurw8HCmTp16yfipU6fSrFmzmy5KiOrIz1XHmAfDWD/8Pl5s3wAHO2v+PZnDSz/soPNna/kj/gRlEthCiAq6oa7vNWvW0LVrVwICAoznUG/cuJFjx46xaNEi4+VFLYF0fQtzOZNfzKy4JGbHHSG3qBSA+rUc6dehId1b1MbW+oa+JwshaoAq7/q+5557OHDgAD169CArK4usrCwefvhh/v33X77//vsbKlqImsbD0Y5XOwWzfsR9vPq/xrg52JKUkc+wX3dz74TV/Lj5KEWlZeYuUwhh4W76POoL7dq1i5YtW1JWZjkfPrJFLSxFflEpP2w6ypfrDpORVwyAr4s9L97TgF5tArC3tTZzhUKIW6XKt6iFEBXnqLXhxXsasu71+3i7Wyi+Lvak5hQy9s+93PXhKr5Yc4j8c13kQghxngS1ELeYzs6aZ6Lqs+b1DrzX4w5qu+nIyCti/OL9RH24kikrDpJTWGLuMoUQFkKCWggz0dpYE9s2kNXDOvDRo82o5+lAVkEJnyw7QNQHK/nkn0Qy84vNXaYQwswqdGWyhx9++KrTs7KybqaWa/rggw8YOXIkgwcPZtKkSVX6WkLcKrbWVvSMqMvDLWrzd0IKU1f+x8H0PKas/I+v1yfx1J2BPH93A7ycteYuVQhhBhUKaldX12tOf/rpp2+qoCvZunUrX3zxhZynLWosG2srHmpem27N/Fn6bypTVv7H3pQcvlh7mFlxR6jrocPb2R5vFy3ezlq8ne3xcj732EWLl7M9LvY2ciU0IWqYCgX1rFmzqqqOq8rLyyM2NpYvv/ySd9991yw1CHGrWFlp6NLUj853+LJyfzqTV/7HrmNZHDqVz6FT+VedV2tjVR7e50Ldy0l7LtzLg93TSYu1lQS6ENXBDd2U41br378/Xbt2JTo6+ppBXVRURFFRkfF5bm5uVZcnRJXQaDR0DPHhvibeJGXkk5JdyKncItJzC0nPKSI9t6j8eW4RuYWlFJXqOZ55luOZZ6+6bCsNeDoZQjvUz4XXYoLxcbG/Re9MCFERFh/U8+bNY8eOHWzduvW62o8fP56xY8dWcVVC3DoajYYGXk408HK6arvCkrKrBnl6ThGn8oo4nVeEXsGpc9P/PZnDP3vTGPdQGA+G+0vXuRAWxqKD+tixYwwePJhly5Zhb3993/ZHjhzJ0KFDjc9PnDhBaGhoVZUohMWwt7WmrocDdT0crtqutEzPmfxi0nOLSMkuZPKKgyScyGbwvHiW7Enl3e534OkkB64JYSkq9cpklW3BggX06NEDa+vyKzaVlZWh0WiwsrKiqKjIZNrlyJXJhLi6kjI901cfYvKKg5TqFZ6Odrz/cFNiwnzNXZoQNVaNuTJZx44dSUhIID4+3jhEREQQGxtLfHz8NUNaCHFtttZWDOoYxIL+UQT7OHM6v5gXv9/O0J/iyS6QC68IYW4W3fXt7OzMHXfcYTLO0dERT0/PS8YLIW7OHbVdWTgwiknLD/LFmkP8vvMEcYcy+PCRZnQI9jZ3eULctix6i1oIcWtpbawZ3rkJv77cjga1HEnLKaLPrK2M/D2BPLkOuRBmYdH7qCuD7KMW4sacLS7jo6X7mRV3BIA67jo+fjScyIae5i1MiBqgxuyjFkKYj87Omre7hTHnhbbUdtNxPPMsvb7cxNg//+VsseXcylaImk6CWghxVe0a1mLpK+3p1aYuALPijtB18jp2JGeauTIhbg8S1EKIa3LS2jD+4WbMeqY1Pi5aDmfk8+j0DXy0ZD9FpbJ1LURVkqAWQly3e4O9+WfIPfRoURu9gs9XH+KhqXHsOZFt7tKEqLEkqIUQFeLqYMunjzdnxv+1wtPRjv2puXSfFsdnyw9SUqY3d3lC1DgS1EKIG9L5Dl/+eaU9ncN8KdUrPl1+gIc/38DBNLkRjhCVSYJaCHHDPJ20TP+/lnz2RHNc7G1IOJFN1ynrmbn2EGX6Gn3mpxC3jAS1EOKmaDQaHmpem2VD76FDsBfFpXreX7Sfx7/YyJGMq98/WwhxbRLUQohK4eNiz6w+rfnwkaY42lmz7WgmXT5bx/ebjlLDr6skRJWSoBZCVBqNRsPjrQNYMqQ9dzbw4GxJGaMW7OHpb7aQkn3W3OUJUS1JUAshKl1dDwfmPH8nox8IRWtjxbqDGcR8upYFO0/I1rUQFSRBLYSoElZWGp69qz5/D7qb8Dqu5BSWMuSnePrP2cGZ/GJzlydEtSFBLYSoUo28nfjt5XYM/V9jbKw0LEpIpdOna1m+N83cpQlRLUhQCyGqnI21FYM6BjG/XxRB3k5k5BXx/HfbeP3XXeQWlpi7PCEsmgS1EOKWaVrHlT8H3sULd9dHo4Gftx2n86R1bDx02tylCWGxJKiFELeUva01b3YNZd4Ld1LXQ8eJLMPtM8f9uZfCErnBhxAXk6AWQphF2waeLB7cnl5tAgD4Ji6JrpPXsft4lnkLE8LCSFALIczGcPvMpszq0xpvZy2HTuXT4/MNTFx2QG7wIcQ5EtRCCLO7t4k3S4e054FmfpTpFZNXHKTH53Fygw8hkKAWQlgId0c7pj7Zkim9WuDmYMueEzl0nbKeL9celht8iNuaBLUQwqJ0C/fnnyHtuffcDT7eW7SPXl9u4tiZAnOXJoRZSFALISyOt4s93/RpzfiHDTf42JJ0hs6T1jJvS7JcglTcdiSohRAWSaPR0KtNAIsHt6dNPQ/yi8sY8XsCz327jfScQnOXJ8QtI0EthLBoAZ4OzO17J2/eH4KdjRUr96cTPXENQ3+O59ftxzmRJXflEjWbjbkLuJrx48fz+++/s3//fnQ6He3atePDDz8kODjY3KUJIW4haysNL7RvwD3BXgz9OZ49J3L4fccJft9xAoAADwciG3jSrpEnkQ088XaxN3PFQlQejbLgHT6dO3fmiSeeoHXr1pSWlvLGG2+wZ88e9u7di6Oj43Ut4/jx49StW5djx45Rp06dKq5YCFHVSsv0bDx8mo2HTrPx8Gl2H8++5KjwBl6OtGvoSWSDWtzZwANPJ62ZqhXi8iqSTRYd1Bc7deoU3t7erFmzhvbt21/XPBLUQtRsuYUlbDuSycbDp9lwKIN/T+Zw8adaE19n7mzgSWRDT+6s74mrg615ihXinIpkk0V3fV8sOzsbAA8Pjyu2KSoqoqioyPg8N1cumCBETeZsb8u9Tby5t4k3ANkFJWxOOm3c6t6fmmscZm84gkYDYf4uRJ4L7tb1PHC2l+AWlqvabFHr9XoefPBBsrKyWL9+/RXbjRkzhrFjx14yXraohbg9nc4rYnPSGTYeMmxxHzqVbzLd2kpD09quRDY07N9uXc8DnZ21maoVt4sa2fX98ssvs3jxYtavX3/VN3XxFvWJEycIDQ2VoBZCAJCeU8jGw6fZdPg0Gw6d5uhp0wup6GytuS/Em27N/OkQ7IW9rYS2qHw1LqgHDBjAH3/8wdq1a6lfv36F5pV91EKIqzmZddZ4YNqG/zI4mV1+jraT1oZOoT48EO7HXY28sLORM1pF5agx+6iVUgwcOJD58+ezevXqCoe0EEJci7+bjkda1eGRVnVQSrHnRA5/7j7JX7tOcjK7kN93nuD3nSdw1dnSOcyXbuH+3NnAAxtrCW1xa1j0FnW/fv2YM2cOf/zxh8m5066uruh0uutahmxRCyFuhF6v2Hkskz93pfB3Qgqncst3qdVysqPLHX50C/cnItAdKyuNGSsV1VGN6frWaC7/xz9r1iz69OlzXcuQoBZC3KwyvWJz0mn+2p3C4oQUMgtKjNN8Xezp2syPB5r50byu2xU/t4S4UI0J6sogQS2EqEwlZXo2HDrNn7tOsvTfVHILS43T6rjreKCZP93C/Qj1c5HQFlckQX0BCWohRFUpKi1j7YEM/tp9kmV70ygoLjNOa1DLkQfC/enWzI8gH2czVikskQT1BSSohRC3wtniMlbuT+ev3SdZuT+dolK9cVoTX2ceaOZH5zt8aejlJFvaouYc9S2EENWFzs6ars386NrMj7yiUpbvTePPXSdZe/CU8cpoE/45QICHA/c18SY6xIc29T3klC9xTbJFLYQQVSi7oISl/6byd0IKGw+dprisfEvbSWvD3UG16BjiQ4dgL2rJzUNuG7JFLYQQFsLVwZaerevSs3Vd8otKWf9fBiv3pbNifzoZeUUs3pPK4j2paDTQvK4bHZt40zHEhya+ztJFLgDZohZCCLPQ6xUJJ7JZsT+dFfvS+Pdkjsl0f1d77gsxhHZkA0+5lGkNIweTXUCCWghRHaRmF7Jyfzor96ex/r8MCkvKu8h1ttZENapFdIjhLmE+LvZmrFRUBun6FkKIasbX1Z4n2wbwZNsAzhaXsfFwBiv2pbNyfzop2YUs35fG8n1pADSt7Wo8IC3M30WujFbDSVALIYSF0dlZc18TH+5r4oNSir0pOazcl87y/ensOpZFwolsEk5k89mKg3g7a+kQ7EVEPQ9aBbrToJaj7NuuYaTrWwghqpH03EJWJ55ixb401h3MMLnICoC7gy0tA9xpGehOywB3wuu64mAn22SWRrq+hRCihvJ2tqdnRF16RtSlqLSMzYfPEPdfBjuSM9l1PJvMghLDAWr70wGwttIQ6udCq0B3WgS40SrQndpuOtnqrkYkqIUQoprS2ljTvrEX7Rt7AVBcquffk9nsSM5ix9FMth/NJDWn0NhVPnuDYT4fFy2tzm1xtwx0J8zfBa2NHFVuqaTrWwgharCTWWfZfi60dyRnsvdkDqV60499OxsrmtV2PbfV7U7LQDe8neXI8qokXd9CCCEA8HfT4e+mo1u4P2C4Jvnu41lsT85kx9FMdiRncSa/mG1HM9l2NNM4X4CHw7mtbjdaBXoQ7OuMtRxdbhYS1EIIcRvR2VnTtoEnbRt4AqCU4sjpAuNW987kTBLTckk+U0DymQLm7zwBgLPWhubn9nFHBHrQPMANJ61EyK0ga1kIIW5jGo2G+rUcqV/LkUdbGbpgcwpLiE/OMnaX70zOIreolHUHM1h3MAMAKw008XUhop67IbzreeDvai8HqVUBCWohhBAmXOxtTQ5SK9Mr9qfmsONc9/i2I5mcyDrL3pQc9qbk8N3GowD4utjTqp47EYGG8A7xc8HWWu4OdrMkqIUQQlyVtZWGMH9XwvxdeSqyHmC45On2o5lsO3qGHUcz+fdkDqk5hfy9O4W/d6cAhkufNq9r6C5vVc9wlLmrztaM76R6kqAWQghRYb6u9sb7bwMUFJey61g2O5Iz2XbkDNuPZpJTWMrGw6fZePg0ABoNNPZ2puW5Le5gH2fqeznKvu5rkLUjhBDipjnY2RDZ0JPIhoaD1PR6xaFTecau8h3JmSRl5JOYlktiWi5ztyQb5/V21lK/liMNvJxoUMuRBl6GfeZ1PRyk6xwJaiGEEFXAykpDkI8zQT7O9GoTAEBGXpHhALWjmew8lsXhU/lk5BWRnmsYNiedMVmGjZWGAA+HcyHuSP1aTjTwcqRBLUe8nLW3zYFrEtRCCCFuiVpOWmLCfIkJ8zWOyyksIelUPkkZ+Rw+lcfhjHwOn3t+tqTM8DwjnxX7TZflpLW5IMDLt8br13LEsYZ1pdesdyOEEKJacbG3JbyuG+F13UzGK6VIzSkk6VQ+hzLySTqVz+GMPJIy8jl2poC8olLjpVEv5u5gi6PWBietDY7nBietNY52559bl0+3s7mgrXV5ezvDcxsL6HqXoBZCCGFxNBoNfq46/Fx1tGtUy2RaUWkZx84UcOiCLfGkDMPjjLxiMgtKyCwoqZQ6tDZWJoHf2MeJz55oUSnLvl7VIqinTZvGxx9/TGpqKuHh4UyZMoU2bdqYuywhhBBmoLWxppG3M428nS+Zll1QQlpuIXlFpeSfG/KKys79LKWguJT8ojLj9PJ258YVl1JQVEZxmR6AolI9RaXFnM4vBgz7zW81iw/qn376iaFDhzJjxgzatm3LpEmTiImJITExEW9vb3OXJ4QQwoK4Otji6nDz52oXl+rLg7y4PPC1Nre+K9zi757Vtm1bWrduzdSpUwHQ6/XUrVuXgQMHMmLEiGvOL3fPEkIIYWkqkk3m30t+FcXFxWzfvp3o6GjjOCsrK6Kjo9m4ceNl5ykqKiInJ8c45Obm3qpyhRBCiEpn0UGdkZFBWVkZPj4+JuN9fHxITU297Dzjx4/H1dXVOISGht6KUoUQQogqYdFBfSNGjhxJdna2cdi7d6+5SxJCCCFumEUfTFarVi2sra1JS0szGZ+Wloavr+9l59FqtWi1WuPznJycKq1RCCGEqEoWvUVtZ2dHq1atWLFihXGcXq9nxYoVREZGmrEyIYQQ4taw6C1qgKFDh9K7d28iIiJo06YNkyZNIj8/n2eeeea65tfrDefCpaSkVGWZQgghxHU7n0nnM+pqLD6oH3/8cU6dOsXo0aNJTU2lefPmLFmy5JIDzK7kfLe5XCBFCCGEpUlLSyMgIOCqbSz+POqbVVpays6dO/Hx8cHK6uZ6+nNzcwkNDWXv3r04O196RRxxKVlnFSfrrOJknVWcrLOKq8x1ptfrSUtLo0WLFtjYXH2bucYHdWXKycnB1dWV7OxsXFxczF1OtSDrrOJknVWcrLOKk3VWceZaZxZ9MJkQQghxu5OgFkIIISyYBHUFaLVa3n77bZPztMXVyTqrOFlnFSfrrOJknVWcudaZ7KMWQgghLJhsUQshhBAWTIJaCCGEsGAS1EIIIYQFk6CugGnTplGvXj3s7e1p27YtW7ZsMXdJFmv8+PG0bt0aZ2dnvL296d69O4mJieYuq9r44IMP0Gg0DBkyxNylWLQTJ07wf//3f3h6eqLT6WjatCnbtm0zd1kWq6ysjFGjRlG/fn10Oh0NGzbknXfeQQ5VMrV27Vq6deuGv78/Go2GBQsWmExXSjF69Gj8/PzQ6XRER0dz8ODBKqtHgvo6/fTTTwwdOpS3336bHTt2EB4eTkxMDOnp6eYuzSKtWbOG/v37s2nTJpYtW0ZJSQmdOnUiPz/f3KVZvK1bt/LFF1/QrFkzc5di0TIzM4mKisLW1pbFixezd+9ePvnkE9zd3c1dmsX68MMPmT59OlOnTmXfvn18+OGHfPTRR0yZMsXcpVmU/Px8wsPDmTZt2mWnf/TRR0yePJkZM2awefNmHB0diYmJobCwsGoKUuK6tGnTRvXv39/4vKysTPn7+6vx48ebsarqIz09XQFqzZo15i7FouXm5qqgoCC1bNkydc8996jBgwebuySLNXz4cHXXXXeZu4xqpWvXrurZZ581Gffwww+r2NhYM1Vk+QA1f/5843O9Xq98fX3Vxx9/bByXlZWltFqtmjt3bpXUIFvU16G4uJjt27cTHR1tHGdlZUV0dDQbN240Y2XVR3Z2NgAeHh5mrsSy9e/fn65du5r8rYnLW7hwIRERETz22GN4e3vTokULvvzyS3OXZdHatWvHihUrOHDgAAC7du1i/fr1dOnSxcyVVR9JSUmkpqaa/I+6urrStm3bKssDi797liXIyMigrKzskjt2+fj4sH//fjNVVX3o9XqGDBlCVFQUd9xxh7nLsVjz5s1jx44dbN261dylVAuHDx9m+vTpDB06lDfeeIOtW7cyaNAg7Ozs6N27t7nLs0gjRowgJyeHJk2aYG1tTVlZGe+99x6xsbHmLq3aSE1NBbhsHpyfVtkkqEWV69+/P3v27GH9+vXmLsViHTt2jMGDB7Ns2TLs7e3NXU61oNfriYiI4P333wegRYsW7NmzhxkzZkhQX8HPP//Mjz/+yJw5cwgLCyM+Pp4hQ4bg7+8v68yCSdf3dahVqxbW1tbGe1ufl5aWhq+vr5mqqh4GDBjAX3/9xapVq6hTp465y7FY27dvJz09nZYtW2JjY4ONjQ1r1qxh8uTJ2NjYUFZWZu4SLY6fnx+hoaEm40JCQkhOTjZTRZZv2LBhjBgxgieeeIKmTZvy1FNP8corrzB+/Hhzl1ZtnP/Mv5V5IEF9Hezs7GjVqhUrVqwwjtPr9axYsYLIyEgzVma5lFIMGDCA+fPns3LlSurXr2/ukixax44dSUhIID4+3jhEREQQGxtLfHw81tbW5i7R4kRFRV1yyt+BAwcIDAw0U0WWr6CgACsr0499a2tr9Hq9mSqqfurXr4+vr69JHuTk5LB58+YqywPp+r5OQ4cOpXfv3kRERNCmTRsmTZpEfn4+zzzzjLlLs0j9+/dnzpw5/PHHHzg7Oxv33bi6uqLT6cxcneVxdna+ZP+9o6Mjnp6esl//Cl555RXatWvH+++/T8+ePdmyZQszZ85k5syZ5i7NYnXr1o333nuPgIAAwsLC2LlzJxMnTuTZZ581d2kWJS8vj//++8/4PCkpifj4eDw8PAgICGDIkCG8++67BAUFUb9+fUaNGoW/vz/du3evmoKq5FjyGmrKlCkqICBA2dnZqTZt2qhNmzaZuySLBVx2mDVrlrlLqzbk9Kxr+/PPP9Udd9yhtFqtatKkiZo5c6a5S7JoOTk5avDgwSogIEDZ29urBg0aqDfffFMVFRWZuzSLsmrVqst+fvXu3VspZThFa9SoUcrHx0dptVrVsWNHlZiYWGX1yN2zhBBCCAsm+6iFEEIICyZBLYQQQlgwCWohhBDCgklQCyGEEBZMgloIIYSwYBLUQgghhAWToBZCCCEsmAS1EEIIYcEkqIUQlU6j0bBgwQJzlyFEjSBBLUQN06dPHzQazSVD586dzV2aEOIGyE05hKiBOnfuzKxZs0zGabVaM1UjhLgZskUtRA2k1Wrx9fU1Gdzd3QFDt/T06dPp0qULOp2OBg0a8Ouvv5rMn5CQwH333YdOp8PT05O+ffuSl5dn0uabb74hLCwMrVaLn58fAwYMMJmekZFBjx49cHBwICgoiIULFxqnZWZmEhsbi5eXFzqdjqCgoEu+WAghDCSohbgNjRo1ikceeYRdu3YRGxvLE088wb59+wDIz88nJiYGd3d3tm7dyi+//MLy5ctNgnj69On079+fvn37kpCQwMKFC2nUqJHJa4wdO5aePXuye/du7r//fmJjYzlz5ozx9ffu3cvixYvZt28f06dPp1atWrduBQhRnVTZfbmEEGbRu3dvZW1trRwdHU2G9957TylluAXpSy+9ZDJP27Zt1csvv6yUUmrmzJnK3d1d5eXlGaf//fffysrKSqWmpiqllPL391dvvvnmFWsA1FtvvWV8npeXpwC1ePFipZRS3bp1U88880zlvGEhajjZRy1EDXTvvfcyffp0k3EeHh7Gx5GRkSbTIiMjiY+PB2Dfvn2Eh4fj6OhonB4VFYVerycxMRGNRsPJkyfp2LHjVWto1qyZ8bGjoyMuLi6kp6cD8PLLL/PII4+wY8cOOnXqRPfu3WnXrt0NvVchajoJaiFqIEdHx0u6oiuLTqe7rna2trYmzzUaDXq9HoAuXbpw9OhRFi1axLJly+jYsSP9+/dnwoQJlV6vENWd7KMW4ja0adOmS56HhIQAEBISwq5du8jPzzdOj4uLw8rKiuDgYJydnalXrx4rVqy4qRq8vLzo3bs3P/zwA5MmTWLmzJk3tTwhairZohaiBioqKiI1NdVknI2NjfGArV9++YWIiAjuuusufvzxR7Zs2cLXX38NQGxsLG+//Ta9e/dmzJgxnDp1ioEDB/LUU0/h4+MDwJgxY3jppZfw9vamS5cu5ObmEhcXx8CBA6+rvtGjR9OqVSvCwsIoKirir7/+Mn5REEKYkqAWogZasmQJfn5+JuOCg4PZv38/YDgie968efTr1w8/Pz/mzp1LaGgoAA4ODixdupTBgwfTunVrHBwceOSRR5g4caJxWb1796awsJBPP/2U1157jVq1avHoo49ed312dnaMHDmSI0eOoNPpuPvuu5k3b14lvHMhah6NUkqZuwghxK2j0WiYP38+3bt3N3cpQojrIPuohRBCCAsmQS2EEEJYMNlHLcRtRvZ2CVG9yBa1EEIIYcEkqIUQQggLJkEthBBCWDAJaiGEEMKCSVALIYQQFkyCWgghhLBgEtRCCCGEBZOgFkIIISyYBLUQQghhwf4fkOVwoct1iJ8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Simple plot that shows the training and validation set losses side by side:\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "  fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "  ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "  ax1.plot(\n",
        "      epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
        "  )\n",
        "  ax1.set_xlabel(\"Epochs\")\n",
        "  ax1.set_ylabel(\"Loss\")\n",
        "  ax1.legend(loc=\"upper right\")\n",
        "  ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "  ax2 = ax1.twiny()\n",
        "  ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        "  ax2.set_xlabel(\"Tokens seen\")\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1Lwf_on9BDn"
      },
      "source": [
        "- Both the training and validation losses start to improve for the first epoch.  The losses start to diverge past the second epoch.  This divergence and the fact that the validation loss is much larger than the training loss indicate that the model is overfitting to the training data.\n",
        "- We can confirm that the model memorizes the training data verbatim by searching for the generated text snippets\n",
        "- The memorization is expected since we are working with a very, small training dataset and training the mode for multiple epochs.\n",
        "\n",
        "## 5.3 - Decoding strategies to control randomness\n",
        "\n",
        "- Let's look at text generation strategies.\n",
        "- We will begin by transferring the model back from GPU to CPU since inference with a relatively small model does not require a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "l3RkDnUx9_UX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e26db8a6-e59c-4984-a328-e65230f0895c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "d3bpeGYU63Xs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed79fef4-fdf8-4081-b98f-a23e444037b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text: \n",
            " Every effort moves you?\"\n",
            "\n",
            "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#   We plug the GPTModel instance (model) into the generate_text_simple function\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "token_ids = generate_text_simple(\n",
        "  model=model,\n",
        "  idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "  max_new_tokens=25,\n",
        "  context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output text: \\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KrN0OAH-nNH"
      },
      "source": [
        "### 5.3.1 - Temperature scaling\n",
        "\n",
        "- Inside the generate_text_simple function, we always sampled the token with the highest probability as the next token, using torch.argmax, also known as greeding decoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "RXBhxO_4-qJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62842477-c980-446f-ddd3-96bc6adee448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward\n"
          ]
        }
      ],
      "source": [
        "#   To illustrate probabilistic sampling with a concrete example, lets briefly\n",
        "# discuss the next-token generation process using a very small vocabulary\n",
        "vocab = {\n",
        "    \"closer\": 0,\n",
        "    \"every\": 1,\n",
        "    \"effort\": 2,\n",
        "    \"forward\": 3,\n",
        "    \"inches\": 4,\n",
        "    \"moves\": 5,\n",
        "    \"pizza\": 6,\n",
        "    \"toward\": 7,\n",
        "    \"you\": 8,\n",
        "}\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}\n",
        "\n",
        "#   Lets assume the LLM is given the start context \"every effor moves yoo\"\n",
        "# and generates the following next-token logits:\n",
        "next_token_logits = torch.tensor(\n",
        "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")\n",
        "\n",
        "#   Convert the logits into probabilities via the softmax function and obtain the token ID\n",
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "next_token_id = torch.argmax(probas).item()\n",
        "print(inverse_vocab[next_token_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYPfQ1MtEcwo",
        "outputId": "5025c7bc-72c1-4129-a918-d79c2b4a4dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73 x closer\n",
            "0 x every\n",
            "0 x effort\n",
            "582 x forward\n",
            "2 x inches\n",
            "0 x moves\n",
            "0 x pizza\n",
            "343 x toward\n"
          ]
        }
      ],
      "source": [
        "#   The output is \"forward\" just like before.  the multinomial function\n",
        "# samples the next token proportional to its probability score.\n",
        "\n",
        "# Implement a function that repeats the sampling 1000 times:\n",
        "def print_sampled_tokens(probas):\n",
        "    torch.manual_seed(123)\n",
        "    sample = [torch.multinomial(probas, num_samples=1).item()\n",
        "                for i in range(1000)]\n",
        "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
        "    for i, freq in enumerate(sampled_ids):\n",
        "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
        "\n",
        "print_sampled_tokens(probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t05ilV82Ecwo"
      },
      "source": [
        "- We can further control the distribution and selection process via a concept call temperature scaling.\n",
        "- Temperature scaling is just a fancy description for dividing the logits by a number greater than 0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "ZDi48wUsEcwp",
        "outputId": "c5e6efd6-7ff9-47f7-a79c-baac6ecec80c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        "    scaled_logits = logits / temperature\n",
        "    return torch.softmax(scaled_logits, dim=0)\n",
        "\n",
        "#   Temperatures greater than 1 result in more uniformly distributed token\n",
        "# probabilities, and temperatures small than 1 will result in more confident\n",
        "# (sharper or more peaky) distributions.\n",
        "temperatures = [1, 0.1, 5]\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits, T)\n",
        "                 for T in temperatures]\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "for i, T in enumerate(temperatures):\n",
        "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
        "                   bar_width, label=f\"Temerature = {T}\")\n",
        "\n",
        "ax.set_ylabel(\"Probability\")\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_2xtBl_Ecwp"
      },
      "source": [
        "### 5.3.2 Top-k sampling\n",
        "\n",
        "- Top-k sampling, when combined with probabilistic sampling and temperature scaling can improvve the text generation resluts.  In top-k sampling, we can restric the sampled tokens to the top-k most likely tokens and exclude all other tokens from the selection process"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 3\n",
        "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
        "print(\"Top logits:\", top_logits)\n",
        "print(\"Top positions:\", top_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNiwDbDp6X9E",
        "outputId": "7eba1907-7f70-42d7-84c0-d08bbc093e5d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
            "Top positions: tensor([3, 7, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#   Apply PyTorch where function to set the logit values of tokens that are\n",
        "# below the lowest logit value within our top-three selection to negative\n",
        "# infinity\n",
        "new_logits = torch.where(\n",
        "    condition=next_token_logits < top_logits[-1],\n",
        "    input=torch.tensor(float(\"-inf\")),\n",
        "    other=next_token_logits\n",
        ")\n",
        "print(new_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7---HnqOLAcS",
        "outputId": "2e58ef0a-7245-4284-979a-b2e21276798f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#   Let's apply the softmax function to turn these into next-token probabilities:\n",
        "topk_probas = torch.softmax(new_logits, dim=0)\n",
        "print(topk_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv7rbCjfLfXy",
        "outputId": "14a47bff-14b9-476e-8a5d-47d13c69bf53"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.3 Modifying the text generation function"
      ],
      "metadata": {
        "id": "wM5Qu6KRLr0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#   Combine temperature sampling and top-k sampling to modify the\n",
        "# generate_text_simple function\n",
        "def generate(model, idx, max_new_tokens, context_size,\n",
        "             temperature=0.0, top_k=None, eos_id=None):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "    logits = logits[:, -1, :]\n",
        "    if top_k is not None:\n",
        "      top_logits, _ = torch.topk(logits, top_k)\n",
        "      min_val = top_logits[:, -1]\n",
        "      logits = torch.where(\n",
        "          logits < min_val,\n",
        "          torch.tensor(float(\"-inf\")).to(logits.device),\n",
        "          logits\n",
        "      )\n",
        "    if temperature > 0.0:\n",
        "      logits = logits / temperature\n",
        "      probas = torch.softmax(logits, dim=1)\n",
        "      idx_next = torch.multinomial(probas, num_samples=1)\n",
        "    else:\n",
        "      idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "\n",
        "    if idx_next == eos_id:\n",
        "      break\n",
        "\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "xnfcavyALoKk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   View the results of new generate function in action\n",
        "torch.manual_seed(123)\n",
        "token_ids = generate(\n",
        "    model = model,\n",
        "    idx = text_to_token_ids(\"Every effor moves you\", tokenizer),\n",
        "    max_new_tokens = 15,\n",
        "    context_size = GPT_CONFIG_124M[\"context_length\"],\n",
        "    top_k = 25,\n",
        "    temperature = 1.4\n",
        ")\n",
        "\n",
        "print(\"Output text: \\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QkxoDnnM36-",
        "outputId": "b28a8009-eac2-476c-fa24-2051b0f78ac6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text: \n",
            " Every effor moves you stand here; andforming, he saw his glory lifted the tips of a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 - Loading and saving model weights in PyTorch\n",
        "\n",
        "-"
      ],
      "metadata": {
        "id": "h2aHvey-NTii"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M9EfzmESNR9H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}