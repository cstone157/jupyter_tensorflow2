{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430af532-3e09-4d4b-a7a8-c36d51ecc7d7",
   "metadata": {},
   "source": [
    "https://keras.io/examples/vision/basnet_segmentation/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847bb508-357f-4aa8-9f04-0ca593bd8d38",
   "metadata": {},
   "source": [
    "## Highly accurate boundaries segmentation using BASNet\n",
    "\n",
    "<b>Author:</b> <a href=\"https://github.com/hamidriasat\">Hamid Ali</a> <br />\n",
    "<b>Date created:</b> 2023/05/30 <br />\n",
    "<b>Last modified:</b> 2023/07/13 <br />\n",
    "<b>Description:</b> Boundaries aware segmentation model trained on the DUTS dataset. <br />\n",
    "\n",
    "<hr />\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Deep semantic segmentation algorithms have improved a lot recently, but still fails to correctly predict pixels around object boundaries. In this example we implement <b>Boundary-Aware Segmentation Network (BASNet)</b>, using two stage predict and refine architecture, and a hybrid loss it can predict highly accurate boundaries and fine structures for image segmentation.\n",
    "References:\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"https://arxiv.org/abs/2101.04704\">Boundary-Aware Segmentation Network for Mobile and Web Applications</a></li>\n",
    "    <li><a href=\"https://github.com/hamidriasat/BASNet/tree/basnet_keras\">BASNet Keras Implementation</a></li>\n",
    "    <li><a href=\"https://openaccess.thecvf.com/content_cvpr_2017/html/Wang_Learning_to_Detect_CVPR_2017_paper.html\">Learning to Detect Salient Objects with Image-level Supervision</a></li>\n",
    "</ul>\n",
    "\n",
    "### Download the Data\n",
    "\n",
    "We will use the <a href=\"http://saliencydetection.net/duts/\">DUTS-TE</a> dataset for training. It has 5,019 images but we will use 140 for training and validation to save notebook running time. DUTS is relatively large salient object segmentation dataset. which contain diversified textures and structures common to real-world images in both foreground and background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "759e744d-18d0-4945-bd77-2d3b1f190b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: wget: not found\n",
      "unzip:  cannot find or open DUTS-TE.zip, DUTS-TE.zip.zip or DUTS-TE.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget http://saliencydetection.net/duts/download/DUTS-TE.zip\n",
    "!unzip -q DUTS-TE.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c559686-9368-4b9e-8643-c0e2187b1a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
