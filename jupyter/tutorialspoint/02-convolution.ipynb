{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a013b87-5143-45e7-bc25-a795ff8eb3e6",
   "metadata": {},
   "source": [
    "## TensorFlow - Convolutional Neural Networks\n",
    "\n",
    "#### Two types of deep neural networks:\n",
    "<ul><li>\n",
    "    Convolutional Neural Networks\n",
    "</li><li>\n",
    "    Recurrent Neural Networks\n",
    "</li></ul>\n",
    "\n",
    "Convolution Neural Network (CNN) are designed to process data through multiple layers of arrays.  Convolutional neural network uses three basic ideas −\n",
    "<ul>\n",
    "    <li>Local respective fields</li>\n",
    "    <li>Convolution</li>\n",
    "    <li>Pooling</li>\n",
    "</ul>\n",
    "\n",
    "## TensorFlow Implementation of CNN\n",
    "\n",
    "### Step 1 - \n",
    "Import the necissary modules of TensorFlow and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "614bf6ea-6b59-4dfe-a042-577ed930e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#from tensorflow.examples.tutorials.mnist import input_data ## Old code\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e914ffe-1d7c-454e-bf1d-0f5627217e18",
   "metadata": {},
   "source": [
    "### Step 2 - \n",
    "Declare a function called run_cnn(), which includes various parameters and optimization variables with declaration of data placeholders. These optimization variables will declare the training pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f8cb0ff-5ba0-40a5-baa5-7b39e6e4c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a tf.data.Dataset\n",
    "#dataset = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN)\n",
    "\n",
    "def run_cnn():\n",
    "    #mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "    mnist = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN)\n",
    "    learning_rate = 0.0001\n",
    "    epochs = 10\n",
    "    batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8fda5f-2d09-4e3d-ae13-00da7845a5e4",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Declare the training data placeholders of 28px by 28px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f02fcd50-fec1-4b37-9446-0718b05c074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the t1 compat to make this V1 code still work\n",
    "tf.compat.v1.disable_eager_execution() # Disable V2's eager execution\n",
    "\n",
    "#x = tf.placeholder(tf.float32, [None, 784])\n",
    "x = tf.compat.v1.placeholder(tf.float32, [None, 784])\n",
    "x_shaped = tf.reshape(x, [-1, 28, 28, 1])\n",
    "#y = tf.placeholder(tf.float32, [None, 10])\n",
    "y = tf.compat.v1.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beb17d3-89b4-4f82-b405-9f9422bbce57",
   "metadata": {},
   "source": [
    "### Step 4 − \n",
    "\n",
    "Now it is important to create some convolutional layers −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae0b9728-ad81-4326-89cc-833d187441bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_conv_layer(\n",
    "    input_data, num_input_channels, num_filters,filter_shape, pool_shape, name):\n",
    "    \n",
    "    conv_filt_shape = [\n",
    "        filter_shape[0], filter_shape[1], num_input_channels, num_filters]\n",
    "    \n",
    "    #weights = tf.Variable(tf.truncated_normal(conv_filt_shape, stddev = 0.03), name = name+'_W')\n",
    "    weights = tf.Variable(tf.random.truncated_normal(conv_filt_shape, stddev = 0.03), name = name+'_W')\n",
    "    #bias = tf.Variable(tf.truncated_normal([num_filters]), name = name+'_b')\n",
    "    bias = tf.Variable(tf.random.truncated_normal([num_filters]), name = name+'_b')\n",
    "    \n",
    "    #Out layer defines the output\n",
    "    out_layer = tf.nn.conv2d(input_data, weights, [1, 1, 1, 1], padding = 'SAME')\n",
    "    \n",
    "    out_layer += bias\n",
    "    out_layer = tf.nn.relu(out_layer)\n",
    "    ksize = [1, pool_shape[0], pool_shape[1], 1]\n",
    "    strides = [1, 2, 2, 1]\n",
    "    out_layer = tf.nn.max_pool(\n",
    "        out_layer, ksize = ksize, strides = strides, padding = 'SAME')\n",
    "    \n",
    "    return out_layer\n",
    "\n",
    "layer1 = create_new_conv_layer(x_shaped, 1, 32, [5, 5], [2, 2], name = 'layer1')\n",
    "layer2 = create_new_conv_layer(layer1, 32, 64, [5, 5], [2, 2], name = 'layer2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29d778-886f-4505-a9e3-650afe71713a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
