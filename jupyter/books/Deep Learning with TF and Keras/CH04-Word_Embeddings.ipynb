{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5bb6c1f-14a5-4d39-acf5-dc18c8b1da9f",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "## Word embedding - origins and fundamentals\n",
    "-    collective name for a set of language modeling and feature learning techings in natural language processing (NLP)\n",
    "-    one-hot encoding is early example, but doesn't work\n",
    "-    other examples borrow from Information Retrieval (IR): Term Frequency-Inverse Document Frequency (TF-IDF), Latent Semantic Analysis (LSA), and topic modeling\n",
    "\n",
    "### Distributed representations\n",
    "-    Attempt to capture the meaning of word by considering its relations with other words in its context.\n",
    "\n",
    "### Static embeddings\n",
    "-    Embeddings are generated against a large corpus, but the nuumber of words, though large, is finite.\n",
    "-    Think of static embedding as a dictionary\n",
    "#### Word2Vec\n",
    "-    Self-supervised\n",
    "-    Continuous Bag of Words (CBOW) and Skip-gram\n",
    "-    Skip-Gram with Negative Sampling (SGNS) model\n",
    "-    GloVe - Global vectors for word representation\n",
    "#### Creating your own embeddings using Gesim\n",
    "-    Gesim is an open-source python library designed to extract semantic meaning from text documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7611c997-ee87-4060-b7fe-f8469126c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "dataset = api.load(\"text8\")\n",
    "model = Word2Vec(dataset)\n",
    "model.save(\"data/text8-word2vec.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb6c3d-9210-406d-980c-cbbea85ee745",
   "metadata": {},
   "source": [
    "### Exploring the embedding space with Gensim\n",
    "-    Reload the model we just built and explore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56cb749-5981-4703-8e6d-40649e54fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load(\"data/text8-word2vec.bin\")\n",
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01986db9-eadf-4986-b05f-8488cc761906",
   "metadata": {},
   "source": [
    "-    Look at the first few words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c002a93e-57d2-49c7-85cc-4d1f9990b3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['the', 'of', 'and', 'one', 'in', 'a', 'to', 'zero', 'nine', 'two'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words = word_vectors.vocab.keys()\n",
    "\n",
    "#print([x for i, x in enumerate(words) if i < 10])\n",
    "#assert(\"king\" in words)\n",
    "\n",
    "my_dict = dict({})\n",
    "i = 0\n",
    "for idx, key in enumerate(model.wv.key_to_index):\n",
    "    my_dict[key] = model.wv[key]\n",
    "    i += 1\n",
    "    if i >= 10:\n",
    "        break\n",
    "\n",
    "my_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba919fc3-40cd-4668-b0aa-8d0f954f4b6c",
   "metadata": {},
   "source": [
    "Look for similar words to a given word \"king\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7333eba3-191d-4658-a242-e4e9314e8789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737 prince\n",
      "0.733 queen\n",
      "0.716 emperor\n",
      "0.709 vii\n",
      "0.691 throne\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "def print_most_similar(word_conf_pairs, k):\n",
    "    for i, (word, conf) in enumerate(word_conf_pairs):\n",
    "        print(\"{:.3f} {:s}\".format(conf, word))\n",
    "        if i >= k-1:\n",
    "            break\n",
    "    if k < len(word_conf_pairs):\n",
    "        print(\"...\")\n",
    "\n",
    "print_most_similar(word_vectors.most_similar(\"king\"), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f726cb68-753c-42f0-ae59-2b7ea6d19851",
   "metadata": {},
   "source": [
    "You can also do vector arithmetic similar to the country-capital example we described earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa9090fa-884e-4b74-8039-5c423940c28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826 germany\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print_most_similar(word_vectors.most_similar(\n",
    "    positive=[\"france\", \"berlin\"], negative=[\"paris\"]), 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d125030-6e42-4f40-8f65-a915a2bc7cf5",
   "metadata": {},
   "source": [
    "The preceding similaring value is reported cosine.  Alternatively copyte the distance with lag scale, amplifying the difference between sorter distance and reducing the difference between longer ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "434ecfc7-0700-46d5-939f-9d3eb1d0bd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971 germany\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print_most_similar(word_vectors.most_similar_cosmul(\n",
    "    positive=[\"france\", \"berlin\"], negative=[\"paris\"]), 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3e276-712d-4156-8c92-498b427e4d1d",
   "metadata": {},
   "source": [
    "Gensim also provides a doesnt_match function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b36d22d6-2140-4164-a82d-4d6648afea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singapore\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.doesnt_match([\"hindus\", \"parsis\", \"singapore\", \"christians\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c6479-1dd7-462c-a5c3-3a2d283ebc84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
