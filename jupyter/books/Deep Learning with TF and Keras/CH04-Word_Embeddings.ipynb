{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5bb6c1f-14a5-4d39-acf5-dc18c8b1da9f",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "## Word embedding - origins and fundamentals\n",
    "-    collective name for a set of language modeling and feature learning techings in natural language processing (NLP)\n",
    "-    one-hot encoding is early example, but doesn't work\n",
    "-    other examples borrow from Information Retrieval (IR): Term Frequency-Inverse Document Frequency (TF-IDF), Latent Semantic Analysis (LSA), and topic modeling\n",
    "\n",
    "### Distributed representations\n",
    "-    Attempt to capture the meaning of word by considering its relations with other words in its context.\n",
    "\n",
    "### Static embeddings\n",
    "-    Embeddings are generated against a large corpus, but the nuumber of words, though large, is finite.\n",
    "-    Think of static embedding as a dictionary\n",
    "#### Word2Vec\n",
    "-    Self-supervised\n",
    "-    Continuous Bag of Words (CBOW) and Skip-gram\n",
    "-    Skip-Gram with Negative Sampling (SGNS) model\n",
    "-    GloVe - Global vectors for word representation\n",
    "#### Creating your own embeddings using Gesim\n",
    "-    Gesim is an open-source python library designed to extract semantic meaning from text documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7611c997-ee87-4060-b7fe-f8469126c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "dataset = api.load(\"text8\")\n",
    "model = Word2Vec(dataset)\n",
    "model.save(\"data/text8-word2vec.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb6c3d-9210-406d-980c-cbbea85ee745",
   "metadata": {},
   "source": [
    "### Exploring the embedding space with Gensim\n",
    "-    Reload the model we just built and explore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d56cb749-5981-4703-8e6d-40649e54fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load(\"data/text8-word2vec.bin\")\n",
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01986db9-eadf-4986-b05f-8488cc761906",
   "metadata": {},
   "source": [
    "-    Look at the first few words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c002a93e-57d2-49c7-85cc-4d1f9990b3c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#words = word_vectors.vocab.keys()\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#print([x for i, x in enumerate(words) if i < 10])\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#assert(\"king\" in words)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mkey_to_index):\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mmy_dict\u001b[49m[key] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mwv[key]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#words = word_vectors.vocab.keys()\n",
    "\n",
    "#print([x for i, x in enumerate(words) if i < 10])\n",
    "#assert(\"king\" in words)\n",
    "\n",
    "for idx, key in enumerate(model.wv.key_to_index):\n",
    "    my_dict[key] = model.wv[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4876da-1b1f-4bad-9170-6d3b3f15d9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
