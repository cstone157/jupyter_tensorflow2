{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc3d48c9-1a51-4cb0-87e5-8f164096d230",
   "metadata": {},
   "source": [
    "## Basic classification: Classify images of clothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afb26b8-0592-4aa5-a06e-8379a48bb2c0",
   "metadata": {},
   "source": [
    "This guide trains a neural network model to classify images of clothing, like sneakers and shirts. It's okay if you don't understand all the details; this is a fast-paced overview of a complete TensorFlow program with the details explained as you go.\n",
    "<br/>&nbsp;<br/>\n",
    "This guide uses <a href=\"https://www.tensorflow.org/guide/keras\">tf.keras</a>, a high-level API to build and train models in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd7e96a-0c7f-48c1-9ec2-67956a008005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 04:20:20.605276: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ffc40a-c09f-4407-9292-a564c83ffe2a",
   "metadata": {},
   "source": [
    "### Import the Fashion MNIST dataset\n",
    "\n",
    "This guide uses the <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion MNIST</a> dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here: <br/>\n",
    "    - Fashion MNIST sprite (SKIPPED)\n",
    "    - Figure 1. <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).\n",
    " \n",
    "Fashion MNIST is intended as a drop-in replacement for the classic <a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST</a> dataset—often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc.) in a format identical to that of the articles of clothing you'll use here.\n",
    "<br/>&nbsp;<br/>\n",
    "This guide uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code.\n",
    "<br/>&nbsp;<br/>\n",
    "Here, 60,000 images are used to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow. Import and <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data\">load the Fashion MNIST data</a> directly from TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ba5842-07a0-491b-9d3c-75821d2aea9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f0eaf8-93ce-4c1d-8165-55713be72fdf",
   "metadata": {},
   "source": [
    "### Loading the dataset returns four NumPy arrays:\n",
    "\n",
    "    - The train_images and train_labels arrays are the training set—the data the model uses to learn.\n",
    "    - The model is tested against the test set, the test_images, and test_labels arrays.\n",
    "\n",
    "The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255. The labels are an array of integers, ranging from 0 to 9. These correspond to the class of clothing the image represents:\n",
    "<br/>&nbsp;<br/>\n",
    "<table>\n",
    "<tr><th>Label</th> \t<th>Class</th></tr>\n",
    "<tr><td>0</td>   <td>T-shirt/top</td></tr>\n",
    "<tr><td>1</td>   <td>Trouser</td></tr>\n",
    "<tr><td>2</td>   <td>Pullover</td></tr>\n",
    "<tr><td>3</td>   <td>Dress</td></tr>\n",
    "<tr><td>4</td>   <td>Coat</td></tr>\n",
    "<tr><td>5</td>   <td>Sandal</td></tr>\n",
    "<tr><td>6</td>   <td>Shirt</td></tr>\n",
    "<tr><td>7</td>   <td>Sneaker</td></tr>\n",
    "<tr><td>8</td>   <td>Bag</td></tr>\n",
    "<tr><td>9</td>   <td>Ankle boot</td></tr>\n",
    "</table>\n",
    "<br/>&nbsp;<br/>\n",
    "Each image is mapped to a single label. Since the class names are not included with the dataset, store them here to use later when plotting the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9605d67c-bd2c-49b0-a489-ccd1044d2da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a74d70-a859-401f-a25c-b13d65f1e36e",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "Let's explore the format of the dataset before training the model. The following shows there are 60,000 images in the training set, with each image represented as 28 x 28 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "371bd622-ec1f-4c7e-b2cb-4689967ee5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467237ce-0aae-4de6-aa27-4dca72078178",
   "metadata": {},
   "source": [
    "Likewise, there are 60,000 labels in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09bcba7-508e-42ed-9c14-c8048481a69f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
